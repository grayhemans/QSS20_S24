{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 3: Text analysis of DOJ press releases\n",
    "\n",
    "**Total points (without extra credit)**: 52 \n",
    "\n",
    "- For background:\n",
    "\n",
    "    - DOJ is the federal law enforcement agency responsible for federal prosecutions; this contrasts with the local prosecutions in the Cook County dataset we analyzed earlier. Here's a short explainer on which crimes get prosecuted federally versus locally: https://www.criminaldefenselawyer.com/resources/criminal-defense/federal-crime/state-vs-federal-crimes.htm#:~:text=Federal%20criminal%20prosecutions%20are%20handled,of%20state%20and%20local%20law. \n",
    "    - Here's the Kaggle that contains the data: https://www.kaggle.com/jbencina/department-of-justice-20092018-press-releases \n",
    "    - Here's the code the dataset creator used to scrape those press releases here if you're interested: https://github.com/jbencina/dojreleases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/grayhemans/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/grayhemans/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "## helpful packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "## nltk imports\n",
    "import nltk\n",
    "### uncomment and run these lines if you haven't downloaded relevant nltk add-ons yet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "## spacy imports\n",
    "import spacy\n",
    "### uncomment and run the below line if you haven't loaded the en_core_web_sm library yet\n",
    "! python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "## vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## sentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "## lda\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "\n",
    "## repeated printouts and wide-format text\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load and clean text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics_clean</th>\n",
       "      <th>components_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Convicted Bomb Plotter Sentenced to 30 Years</td>\n",
       "      <td>PORTLAND, Oregon. – Mohamed Osman Mohamud, 23, who was convicted in 2013 of attempting to use a weapon of mass destruction (explosives) in connection with a plot to detonate a vehicle bomb at an annual Christmas tree lighting ceremony in Portland, was sentenced today to serve 30 years in prison, followed by a lifetime term of supervised release. Mohamud, a naturalized U.S. citizen from Somalia and former resident of Corvallis, Oregon, was arrested on Nov. 26, 2010, after he attempted to detonate what he believed to be an explosives-laden van that was parked near the tree lighting ceremony in Portland.  The arrest was the culmination of a long-term undercover operation, during which Mohamud was monitored closely for months as his bomb plot developed.  The device was in fact inert, and the public was never in danger from the device. At sentencing, United States District Court Judge Garr M. King, who presided over Mohamed’s 14-day trial, said “the intended crime was horrific,” and that the defendant, even though he was presented with options by undercover FBI employees, “never once expressed a change of heart.”  King further noted that the Christmas tree ceremony was attended by up to 10,000 people, and that the defendant “wanted everyone to leave either dead or injured.”  King said his sentence was necessary in view of the seriousness of the crime and to serve as deterrence to others who might consider similar acts.     “With today’s sentencing, Mohamed Osman Mohamud is being held accountable for his attempted use of what he believed to be a massive bomb to attack innocent civilians attending a public Christmas tree lighting ceremony in Portland,” said John P. Carlin, Assistant Attorney General for National Security.  “The evidence clearly indicated that Mohamud was intent on killing as many people as possible with his attack.  Fortunately, law enforcement was able to identify him as a threat, insert themselves in the place of a terrorist that Mohamud was trying to contact, and thwart Mohamud’s efforts to conduct an attack on our soil.  This case highlights how the use of undercover operations against would-be terrorists allows us to engage and disrupt those who wish to commit horrific acts of violence against the innocent public.  The many agents, analysts, and prosecutors who have worked on this case deserve great credit for their roles in protecting Portland from the threat posed by this defendant and ensuring that he was brought to justice.” “This trial provided a rare glimpse into the techniques Al Qaeda employs to radicalize home-grown extremists,” said Amanda Marshall, U.S. Attorney for the District of Oregon.  “With the sentencing today, the court has held this defendant accountable.   I thank the dedicated professionals in the law enforcement and intelligence communities who were responsible for this successful outcome.  I look forward to our continued work with Muslim communities in Oregon who are committed to ensuring that all young people are safe from extremists who seek to radicalize others to engage in violence.”  According to the trial evidence, in February 2009, Mohamud began communicating via e-mail with Samir Khan, a now-deceased al Qaeda terrorist who published Jihad Recollections, an online magazine that advocated violent jihad, and who also published Inspire, the official magazine of al-Qaeda in the Arabian Peninsula.  Between February and August 2009, Mohamed exchanged approximately 150 emails with Khan.  Mohamud wrote several articles for Jihad Recollections that were published under assumed names. In August 2009, Mohamud was in email contact with Amro Al-Ali, a Saudi national who was in Yemen at the time and is today in custody in Saudi Arabia for terrorism offenses.  Al-Ali sent Mohamud detailed e-mails designed to facilitate Mohamud’s travel to Yemen to train for violent jihad.  In December 2009, while Al-Ali was in the northwest frontier province of Pakistan, Mohamud and Al-Ali discussed the possibility of Mohamud traveling to Pakistan to join Al-Ali in terrorist activities. Mohamud responded to Al-Ali in an e-mail: “yes, that would be wonderful, just tell me what I need to do.”  Al-Ali referred Mohamud to a second associate overseas and provided Mohamud with a name and email address to facilitate the process. In the following months, Mohamud made several unsuccessful attempts to contact Al-Ali’s associate.  Ultimately, an FBI undercover operative contacted Mohamud via email under the guise of being an associate of Al-Ali’s.  Mohamud and the FBI undercover operative agreed to meet in Portland in July 2010.  At the meeting, Mohamud told the FBI undercover operative he had written articles that were published in Jihad Recollections.  Mohamud also said that he wanted to become “operational.”  Asked what he meant by “operational,” Mohamud said he wanted to put an explosion together, but needed help. According to evidence presented at trial, at a meeting in August 2010, Mohamud told undercover FBI operatives he had been thinking of committing violent jihad since the age of 15.  Mohamud then told the undercover FBI operatives that he had identified a potential target for a bomb: the annual Christmas tree lighting ceremony in Portland’s Pioneer Courthouse Square on Nov. 26, 2010.  The undercover FBI operatives cautioned Mohamud several times about the seriousness of this plan, noting there would be many people at the event, including children, and emphasized that Mohamud could abandon his attack plans at any time with no shame.  Mohamud indicated the deaths would be justified and that he would not mind carrying out a suicide attack on the crowd. According to evidence presented at trial, in the ensuing months Mohamud continued to express his interest in carrying out the attack and worked on logistics.  On Nov. 4, 2010, Mohamud and the undercover FBI operatives traveled to a remote location in Lincoln County, Oregon, where they detonated a bomb concealed in a backpack as a trial run for the upcoming attack.  During the drive back to Corvallis, Mohamud was asked if was capable looking at all the bodies of those who would be killed during the explosion.  In response, Mohamud noted, “I want whoever is attending that event to be, to leave either dead or injured.”  Mohamud later recorded a video of himself, with the assistance of the undercover FBI operatives, in which he read a statement that offered his rationale for his bomb attack.  On Nov. 18, 2010, undercover FBI operatives picked up Mohamud to travel to Portland to finalize the details of the attack.  On Nov. 26, 2010, just hours before the planned attack, Mohamud examined the 1,800 pound bomb in the van and remarked that it was “beautiful.”  Later that day, Mohamud was arrested after he attempted to remotely detonate the inert vehicle bomb rked near the Christmas tree lighting ceremony This case was investigated by the FBI, with assistance from the Oregon State Police, the Corvallis Police Department, the Lincoln County Sheriff’s Office and the Portland Police Bureau.  The prosecution was handled by Assistant U.S. Attorneys Ethan D. Knight and Pamala Holsinger from the U.S. Attorney’s Office for the District of Oregon.  Trial Attorney Jolie F. Zimmerman, from the Counterterrorism Section of the Justice Department’s National Security Division, assisted. # # # 14-1077</td>\n",
       "      <td>2014-10-01T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>National Security Division (NSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-919</td>\n",
       "      <td>$1 Million in Restitution Payments Announced to Preserve North Carolina Wetlands</td>\n",
       "      <td>WASHINGTON – North Carolina’s Waccamaw River watershed will benefit from a $1 million restitution order from a federal court, funding environmental projects to acquire and preserve wetlands in an area damaged by illegal releases of wastewater from a corporate hog farm, announced Ignacia S. Moreno, Assistant Attorney General of the Justice Department’s Environment and Natural Resources Division; U.S. Attorney for the Eastern District of North Carolina Thomas G. Walker; Director Greg McLeod from the North Carolina State Bureau of Investigation; and Camilla M. Herlevich, Executive Director of the North Carolina Coastal Land Trust.   Freedman Farms Inc. was sentenced in February 2012 to five years of probation and ordered to pay $1.5 million in fines, restitution and community service payments for violating the Clean Water Act when it discharged hog waste into a stream that leads to the Waccamaw River.  William B. Freedman, president of Freedman Farms, was sentenced to six months in prison to be followed by six months of home confinement.  Freedman Farms also is required to implement a comprehensive environmental compliance program and institute an annual training program.   In an order issued on April 19, 2012, the court ordered that the defendants would be responsible for restitution of $1 million in the form of five annual payments starting in January 2013, which the court will direct to the North Carolina Coastal Land Trust (NCCLT).  The NCCLT plans to use the money to acquire and conserve land along streams in the Waccamaw watershed.  The court also directed a $75,000 community service payment to the Southern Environmental Enforcement Network, an organization dedicated to environmental law enforcement training and information sharing in the region.    “The resolution of the case against Freedman Farms demonstrates the commitment of the Department of Justice to enforcing the Clean Water Act to ensure the protection of human health and the environment,” said Assistant Attorney General Moreno.  “The court-ordered restitution in this case will conserve wetlands for the benefit of the people of North Carolina.  By enforcing the nation’s environmental laws, we will continue to ensure that concentrated animal feeding operations (CAFOs) operate without threatening our drinking water, the health of our communities and the environment.”   “This office is committed to doing our part to hold accountable those who commit crimes against our environment, which can cause serious health problems to residents and damage the environment that makes North Carolina such a beautiful place to live and visit,” said U.S. Attorney Walker.   “This case shows what we can accomplish when our SBI agents work closely with their local, state and federal partners to investigate environmental crimes and hold the polluters accountable,” said Director McLeod.  “We’ll continue our efforts to fight illegal pollution that damages our water and puts the public’s health at risk.”    “The Waccamaw is unique and wild,” said Director Herlevich of the North Carolina Coastal Land Trust. “Its watershed includes some of the most extensive cypress gum swamps in the state, and its headwaters at Lake Waccamaw contain fish that are found nowhere else on Earth.  We appreciate the trust of the court and the U. S. Attorney, and we look forward to using these funds for conservation projects in a river system that is one of our top conservation priorities.”   According to evidence presented in court, in December 2007 Freedman Farms discharged hog waste into Browder’s Branch, a tributary to the Waccamaw River that flows through the White Marsh, a large wetlands complex.  Freedman Farms, located in Columbus County, N.C., is in the business of raising hogs for market, and this particular farm had some 4,800 hogs.  The hog waste was supposed to be directed to two lagoons for treatment and disposal.  Instead, hog waste was discharged from Freedman Farms directly into Browder’s Branch.    The Clean Water Act is a federal law that makes it illegal to knowingly or negligently discharge a pollutant into a water of the United States.    The Freedman case was investigated by the U.S. Environmental Protection Agency (EPA) Criminal Investigation Division, the U.S. Army Corps of Engineers and the North Carolina State Bureau of Investigation, with assistance from the EPA Science and Ecosystem Support Division.  The case was prosecuted by Assistant U.S. Attorney J. Gaston B. Williams of the Eastern District of North Carolina and Trial Attorney Mary Dee Carraway of the Environmental Crimes Section of the Justice Department’s Environment and Natural Resources Division.   The North Carolina Coastal Land Trust is celebrating its 20th anniversary of saving special lands in eastern North Carolina. The organization has protected nearly 50,000 acres of lands with scenic, recreational, historic and ecological values. North Carolina Coastal Land Trust has saved streams and wetlands that provide clean water, forests that are havens for wildlife, working farms that provide local food and nature parks that everyone can enjoy.  More information about the Coastal Land Trust is available at www.coastallandtrust.org.</td>\n",
       "      <td>2012-07-25T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1002</td>\n",
       "      <td>$1 Million Settlement Reached for Natural Resource Damages at Superfund Site in Massachusetts</td>\n",
       "      <td>BOSTON– A $1-million settlement has been reached for natural resource damages (NRD) at the Blackburn &amp; Union Privileges Superfund Site in Walpole, Mass., the Departments of Justice and Interior (DOI), and the Office of the Massachusetts Attorney General announced today.                The Blackburn &amp; Union Privileges Superfund Site includes 22 acres of contaminated land and water in Walpole. The contamination resulted from the operations of various industrial facilities dating back to the 19th century that exposed the site to asbestos, arsenic, lead and other hazardous substances.                The private parties involved in the settlement include two former owners and operators of the site, W.R. Grace &amp; Co.– Conn. and Tyco Healthcare Group LP, as well as the current owners, BIM Investment Corp. and Shaffer Realty Nominee Trust.               From about 1915 to 1936, a predecessor of W.R. Grace manufactured asbestos brake linings and clutch linings on a large portion of the property. From 1946 to about 1983, a predecessor of Tyco Healthcare operated a cotton fabric manufacturing business, which used caustic solutions, on a portion of the property.               In a 2010 settlement with U.S. Environmental Protection Agency (EPA), the four private parties agreed to perform a remedial action to clean up the site at an estimated cost of $13 million. The consent decree lodged today resolves both state and federal NRD liability claims; it requires the parties to pay $1,094,169.56 to the state and federal natural resource trustees, the Massachusetts Executive Office of Energy and Environmental Affairs (EEA) and DOI, for injuries to ecological resources including groundwater and wetlands, which provide habitat for waterfowl and wading birds, including black ducks and great blue herons.  The trustees will use the settlement funds for natural resource restoration projects in the area.               “This settlement demonstrates our commitment to recovering damages from the parties responsible for injury to natural resources, in partnership with state trustees,” said Bruce Gelber, Acting Deputy Assistant Attorney General of the Justice Department’s Environment and Natural Resources Division.               “The citizens of Walpole have had to live with the environmental impact of this contamination for many years,” Attorney General Martha Coakley said. “We are pleased that today’s agreement will not only require the responsible parties to reimburse taxpayer dollars, but will also provide funding to begin restoring or replacing the wetland and other natural resources.”                 The consent decree was lodged in the U.S. District Court for Massachusetts.     A portion of the funds, $300,000, will be distributed to the EEA-sponsored groundwater restoration projects; $575,000 will be used for ecological restoration projects jointly sponsored by EEA and the U.S. Fish and Wildlife Service (FWS).               In addition, $125,000 will go for projects jointly sponsored by EEA and FWS that achieve both ecological and groundwater restoration; $57,491.34 will be allocated for reimbursement for the FWS’s assessment costs; and $36,678.22 will be distributed as reimbursement for the commonwealth’s assessment costs.       “This settlement provides the means for a range of projects designed to compensate the public for decades of groundwater and other ecological damage at this site.  I encourage local citizens and organizations to become engaged in the public process that will take place as we solicit, take comment on, and choose these projects in the months ahead,” said Energy and Environmental Affairs Secretary Richard K. Sullivan Jr., who serves as the Commonwealth’s Natural Resources Damages trustee.       “This settlement will help restore habitat for fish and wildlife in the Neponset River watershed,” said Tom Chapman of the FWS New England Field Office. “We look forward to working with the commonwealth and local stakeholders to implement restoration.”               “More than 100 years-worth of industrial activities at this site caused major environmental contamination to the Neponset River, nearby wetlands and to groundwater below the site,” said Commissioner Kenneth Kimmell of the Massachusetts Department of Environmental Protection (MassDEP), which will staff the Trustee Council for the Commonwealth. “We will ensure that the community and the public will be active participants in the process to use these NRD funds to restore the injured natural resources.”                Under the federal Comprehensive Environmental Response, Compensation and Liability Act, EEA and DOI, acting through the FWS, are the designated state and federal natural resource Trustees for the site. The site has been listed on the EPA’s National Priorities List since 1994.        The consent decree is subject to a public comment period and court approval. A copy of the consent decree and instructions about how to submit comments is available on www.usdoj.gov/enrd/Consent_Decrees.html  .               After the consent decree is approved, EEA and FWS will develop proposed restoration plans to use the settlement funds for restoration projects. The proposed restoration plans will also be made available to the public for review and comment.                Assistant Attorney General Matthew Brock of Massachusetts Attorney General Coakley's Environmental Protection Division handled this matter.  Attorney Jennifer Davis of MassDEP, Attorney Anna Blumkin of EEA and MassDEP’s NRD Coordinator Karen Pelto also worked on this settlement.</td>\n",
       "      <td>2011-08-03T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-015</td>\n",
       "      <td>10 Las Vegas Men Indicted \\r\\nfor Falsifying Vehicle Emissions Tests</td>\n",
       "      <td>WASHINGTON—A federal grand jury in Las Vegas today returned indictments against 10 Nevada-certified emissions testers for falsifying vehicle emissions test reports, the Justice Department announced.   Each defendant faces one felony Clean Air Act count for falsifying reports between November 2007 and May 2009. The number of falsifications varied by defendant, with some defendants having falsified approximately 250 records, while others falsified more than double that figure. One defendant is alleged to have falsified over 700 reports.   The individuals indicted include:     Escudero resides in Pahrump, Nev. All other individuals are from Clark County, Nev.    The 10 defendants are alleged to have engaged in a practice known as \"clean scanning\" vehicles. The scheme involved entering the Vehicle Identification Number (VIN) for a vehicle that would not pass the emissions test into the computerized system, then connecting a different vehicle the testers knew would pass the test. These falsifications were allegedly performed for anywhere from $10 to $100 over and above the usual emissions testing fee.    The U.S. Environmental Protection Agency (EPA), under the Clean Air Act, requires the state of Nevada to conduct vehicle emissions testing in certain areas because the areas exceed national standards for carbon monoxide and ozone. Las Vegas is currently required to perform emissions testing.    To obtain a registration renewal, vehicle owners bring the vehicles to a licensed inspection station for testing. The emissions inspector logs into a computer to activate the system by using a unique password issued to the emissions inspector. The emissions inspector manually inputs the vehicle’s VIN to identify the tested vehicle, then connects the vehicle for model year 1996 and later to an onboard diagnostics port connected to an analyzer. The analyzer downloads data from the vehicle’s computer, analyzes the data and provides a \"pass\" or \"fail\" result. The pass or fail result and vehicle identification data are reported on the Vehicle Inspection Report. It is a crime to knowingly alter or conceal any record or other document required to be maintained by the Clean Air Act.     \"Falsifications of vehicle emissions testing, such as those alleged in the indictments unsealed today, are serious matters and we intend to use all of our enforcement tools to stop this harmful practice. These actions undermine a system that is designed to reduce air pollutants including smog and provide better air quality for the citizens of Nevada,\" said Ignacia S. Moreno, Assistant Attorney General for the Justice Department’s Environment and Natural Resources Division.    \"The residents of Nevada deserve to know that the vast majority of licensed vehicle emission inspectors are not corrupt and are not circumventing emission testing procedures,\" said U.S. Attorney Bogden. \"These indictments should serve as a clear warning to offenders that the Department of Justice will prosecute you if you make fraudulent statements and reports concerning compliance with the federal Clean Air Act.\"    \"Lying about car emissions means dirtier air, which is especially of concern in areas like Las Vegas that are already experiencing air quality problems,\" said Cynthia Giles, Assistant Administrator for Enforcement and Compliance Assurance at EPA. \"We will take aggressive action to ensure communities have clean air.\"    The maximum penalty for the felony violations contained in the indictments includes up to two years in prison and a fine of up to $250,000.    An indictment is merely an accusation, and a defendant is presumed innocent unless and until proven guilty in a court of law.    The case was investigated by the EPA, Criminal Investigation Division; and the Nevada Department of Motor Vehicles Compliance Enforcement Division. The case is being prosecuted by the U.S. Attorney’s Office for the District of Nevada and the Justice Department’s Environmental Crimes Section.</td>\n",
       "      <td>2010-01-08T00:00:00-05:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Work at Centredale Manor Superfund Site in North Providence, R.I.</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Environmental Protection Agency (EPA), and the Rhode Island Department of Environmental Management (RIDEM) announced today that two subsidiaries of Stanley Black &amp; Decker Inc.—Emhart Industries Inc. and Black &amp; Decker Inc.—have agreed to clean up dioxin contaminated sediment and soil at the Centredale Manor Restoration Project Superfund Site in North Providence and Johnston, Rhode Island.  “We are pleased to reach a resolution through collaborative work with the responsible parties, EPA, and other stakeholders,” said Acting Assistant Attorney General Jeffrey H. Wood for the Justice Department's Environment and Natural Resources Division . “Today’s settlement ends protracted litigation and allows for important work to get underway to restore a healthy environment for citizens living in and around the Centredale Manor Site and the Woonasquatucket River.” “This settlement demonstrates the tremendous progress we are achieving working with responsible parties, states, and our federal partners to expedite sites through the entire Superfund remediation process,” said EPA Acting Administrator Andrew Wheeler. “The Centredale Manor Site has been on the National Priorities List for 18 years; we are taking charge and ensuring the Agency makes good on its promise to clean it up for the betterment of the environment and those communities affected.” “Successfully concluding this settlement paves the way for EPA to make good on our commitment to aggressively pursue cleaning up the Centredale Manor Superfund Site,” said EPA New England Regional Administrator Alexandra Dunn. “We are excited to get to work on the cleanup at this site, and get it closer to the goal of being fully utilized by the North Providence and Johnston communities.” “We are pleased that the collective efforts of the State of Rhode Island, EPA, and DOJ in these negotiations have concluded in this major milestone toward the cleanup of the Centredale Manor Restoration Superfund site and are consistent with our long-standing efforts to make the polluter pay,” said RIDEM Director Janet Coit. “The settlement will speed up a remedy that protects public health and the river environment, and moves us closer to the day that we can reclaim recreational uses of this beautiful river resource.” The settlement, which includes cleanup work in the Woonasquatucket River (River) and bordering residential and commercial properties along the River, requires the companies to perform the remedy selected by EPA for the Site in 2012, which is estimated to cost approximately $100 million, and resolves longstanding litigation. The cleanup remedy includes excavation of contaminated sediment and floodplain soil from the Woonasquatucket River, including from adjacent residential properties. Once the cleanup remedy is completed, full access to the Woonasquatucket River should be restored for local citizens. The cleanup will be a step toward the State’s goal of a fishable and swimmable river. The work will also include upgrading caps over contaminated soil in the peninsula area of the Site that currently house two high-rise apartment buildings. The settlement also ensures that the long-term monitoring and maintenance of the site, as directed in the remedy, will be implemented to ensure that public health is protected.  Under the settlement, Emhart and Black &amp; Decker will reimburse EPA for approximately $42 million in past costs incurred at the Site. The companies will also reimburse EPA and the State of Rhode Island for future costs incurred by those agencies in overseeing the work required by the settlement. The settlement will also include payments on behalf of two federal agencies to resolve claims against those agencies. These payments, along with prior settlements related to the Site, will result in a 100 percent recovery for the United States of its past and future response costs related to the Site. Litigation related to the Site has been ongoing for nearly eight years. While the Federal District Court found Black &amp; Decker and Emhart to be liable for their hazardous waste and responsible to conduct the cleanup of the Site, it had also ruled that EPA needed to reconsider certain aspects of that cleanup. EPA appealed the decision requiring it to reconsider aspects of the cleanup. This settlement, once entered by the District Court, will resolve the litigation between the United States, Rhode Island, and Emhart and Black and Decker, allowing the cleanup of the Site to begin. The Site spans a one and a half mile stretch of the Woonasquatucket River and encompasses a nine-acre peninsula, two ponds and a significant forested wetland. From the 1940s to the early 1970s, Emhart’s predecessor operated a chemical manufacturing facility on the peninsula and used a raw material that was contaminated with 2,3,7,8-tetrachlorodibenzo-p-dioxin, a toxic form of dioxin. The Site property was also previously used by a barrel refurbisher. Elevated levels of dioxins and other contaminants have been detected in soil, groundwater, sediment, surface water and fish.  The Site was added to the National Priorities List (NPL) in 2000, and in December 2017, EPA included the Centredale Manor Restoration Project Superfund Site on a list of Superfund sites targeted for immediate and intense attention. Several short-term actions were previously performed at the Site to address immediate threats to the residents and minimize potential erosion and downstream transport of contaminated soil and sediment. This settlement is the latest agreement EPA has reached since the Site was listed on the NPL. Prior agreements addressed the performance and recovery of costs for the past environmental investigations and interim cleanup actions from Emhart, the barrel reconditioning company, the current owners of the peninsula portion of the Site, and other potentially responsible parties. The Consent Decree, lodged in the U.S. District Court of Rhode Island, will be posted in the Federal Register and available for public comment for a period of 30 days. The Consent Decree can be viewed on the Justice Department website: www.justice.gov/enrd/Consent_Decrees.html.  EPA information on the Centredale Manor Superfund Site: www.epa.gov/superfund/centredale.</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0     None   \n",
       "1  12-919    \n",
       "2  11-1002   \n",
       "3   10-015   \n",
       "4   18-898   \n",
       "\n",
       "                                                                                                          title  \\\n",
       "0                                                                  Convicted Bomb Plotter Sentenced to 30 Years   \n",
       "1                              $1 Million in Restitution Payments Announced to Preserve North Carolina Wetlands   \n",
       "2                 $1 Million Settlement Reached for Natural Resource Damages at Superfund Site in Massachusetts   \n",
       "3                                          10 Las Vegas Men Indicted \\r\\nfor Falsifying Vehicle Emissions Tests   \n",
       "4  $100 Million Settlement Will Speed Cleanup Work at Centredale Manor Superfund Site in North Providence, R.I.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          contents  \\\n",
       "0  PORTLAND, Oregon. – Mohamed Osman Mohamud, 23, who was convicted in 2013 of attempting to use a weapon of mass destruction (explosives) in connection with a plot to detonate a vehicle bomb at an annual Christmas tree lighting ceremony in Portland, was sentenced today to serve 30 years in prison, followed by a lifetime term of supervised release. Mohamud, a naturalized U.S. citizen from Somalia and former resident of Corvallis, Oregon, was arrested on Nov. 26, 2010, after he attempted to detonate what he believed to be an explosives-laden van that was parked near the tree lighting ceremony in Portland.  The arrest was the culmination of a long-term undercover operation, during which Mohamud was monitored closely for months as his bomb plot developed.  The device was in fact inert, and the public was never in danger from the device. At sentencing, United States District Court Judge Garr M. King, who presided over Mohamed’s 14-day trial, said “the intended crime was horrific,” and that the defendant, even though he was presented with options by undercover FBI employees, “never once expressed a change of heart.”  King further noted that the Christmas tree ceremony was attended by up to 10,000 people, and that the defendant “wanted everyone to leave either dead or injured.”  King said his sentence was necessary in view of the seriousness of the crime and to serve as deterrence to others who might consider similar acts.     “With today’s sentencing, Mohamed Osman Mohamud is being held accountable for his attempted use of what he believed to be a massive bomb to attack innocent civilians attending a public Christmas tree lighting ceremony in Portland,” said John P. Carlin, Assistant Attorney General for National Security.  “The evidence clearly indicated that Mohamud was intent on killing as many people as possible with his attack.  Fortunately, law enforcement was able to identify him as a threat, insert themselves in the place of a terrorist that Mohamud was trying to contact, and thwart Mohamud’s efforts to conduct an attack on our soil.  This case highlights how the use of undercover operations against would-be terrorists allows us to engage and disrupt those who wish to commit horrific acts of violence against the innocent public.  The many agents, analysts, and prosecutors who have worked on this case deserve great credit for their roles in protecting Portland from the threat posed by this defendant and ensuring that he was brought to justice.” “This trial provided a rare glimpse into the techniques Al Qaeda employs to radicalize home-grown extremists,” said Amanda Marshall, U.S. Attorney for the District of Oregon.  “With the sentencing today, the court has held this defendant accountable.   I thank the dedicated professionals in the law enforcement and intelligence communities who were responsible for this successful outcome.  I look forward to our continued work with Muslim communities in Oregon who are committed to ensuring that all young people are safe from extremists who seek to radicalize others to engage in violence.”  According to the trial evidence, in February 2009, Mohamud began communicating via e-mail with Samir Khan, a now-deceased al Qaeda terrorist who published Jihad Recollections, an online magazine that advocated violent jihad, and who also published Inspire, the official magazine of al-Qaeda in the Arabian Peninsula.  Between February and August 2009, Mohamed exchanged approximately 150 emails with Khan.  Mohamud wrote several articles for Jihad Recollections that were published under assumed names. In August 2009, Mohamud was in email contact with Amro Al-Ali, a Saudi national who was in Yemen at the time and is today in custody in Saudi Arabia for terrorism offenses.  Al-Ali sent Mohamud detailed e-mails designed to facilitate Mohamud’s travel to Yemen to train for violent jihad.  In December 2009, while Al-Ali was in the northwest frontier province of Pakistan, Mohamud and Al-Ali discussed the possibility of Mohamud traveling to Pakistan to join Al-Ali in terrorist activities. Mohamud responded to Al-Ali in an e-mail: “yes, that would be wonderful, just tell me what I need to do.”  Al-Ali referred Mohamud to a second associate overseas and provided Mohamud with a name and email address to facilitate the process. In the following months, Mohamud made several unsuccessful attempts to contact Al-Ali’s associate.  Ultimately, an FBI undercover operative contacted Mohamud via email under the guise of being an associate of Al-Ali’s.  Mohamud and the FBI undercover operative agreed to meet in Portland in July 2010.  At the meeting, Mohamud told the FBI undercover operative he had written articles that were published in Jihad Recollections.  Mohamud also said that he wanted to become “operational.”  Asked what he meant by “operational,” Mohamud said he wanted to put an explosion together, but needed help. According to evidence presented at trial, at a meeting in August 2010, Mohamud told undercover FBI operatives he had been thinking of committing violent jihad since the age of 15.  Mohamud then told the undercover FBI operatives that he had identified a potential target for a bomb: the annual Christmas tree lighting ceremony in Portland’s Pioneer Courthouse Square on Nov. 26, 2010.  The undercover FBI operatives cautioned Mohamud several times about the seriousness of this plan, noting there would be many people at the event, including children, and emphasized that Mohamud could abandon his attack plans at any time with no shame.  Mohamud indicated the deaths would be justified and that he would not mind carrying out a suicide attack on the crowd. According to evidence presented at trial, in the ensuing months Mohamud continued to express his interest in carrying out the attack and worked on logistics.  On Nov. 4, 2010, Mohamud and the undercover FBI operatives traveled to a remote location in Lincoln County, Oregon, where they detonated a bomb concealed in a backpack as a trial run for the upcoming attack.  During the drive back to Corvallis, Mohamud was asked if was capable looking at all the bodies of those who would be killed during the explosion.  In response, Mohamud noted, “I want whoever is attending that event to be, to leave either dead or injured.”  Mohamud later recorded a video of himself, with the assistance of the undercover FBI operatives, in which he read a statement that offered his rationale for his bomb attack.  On Nov. 18, 2010, undercover FBI operatives picked up Mohamud to travel to Portland to finalize the details of the attack.  On Nov. 26, 2010, just hours before the planned attack, Mohamud examined the 1,800 pound bomb in the van and remarked that it was “beautiful.”  Later that day, Mohamud was arrested after he attempted to remotely detonate the inert vehicle bomb rked near the Christmas tree lighting ceremony This case was investigated by the FBI, with assistance from the Oregon State Police, the Corvallis Police Department, the Lincoln County Sheriff’s Office and the Portland Police Bureau.  The prosecution was handled by Assistant U.S. Attorneys Ethan D. Knight and Pamala Holsinger from the U.S. Attorney’s Office for the District of Oregon.  Trial Attorney Jolie F. Zimmerman, from the Counterterrorism Section of the Justice Department’s National Security Division, assisted. # # # 14-1077   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       WASHINGTON – North Carolina’s Waccamaw River watershed will benefit from a $1 million restitution order from a federal court, funding environmental projects to acquire and preserve wetlands in an area damaged by illegal releases of wastewater from a corporate hog farm, announced Ignacia S. Moreno, Assistant Attorney General of the Justice Department’s Environment and Natural Resources Division; U.S. Attorney for the Eastern District of North Carolina Thomas G. Walker; Director Greg McLeod from the North Carolina State Bureau of Investigation; and Camilla M. Herlevich, Executive Director of the North Carolina Coastal Land Trust.   Freedman Farms Inc. was sentenced in February 2012 to five years of probation and ordered to pay $1.5 million in fines, restitution and community service payments for violating the Clean Water Act when it discharged hog waste into a stream that leads to the Waccamaw River.  William B. Freedman, president of Freedman Farms, was sentenced to six months in prison to be followed by six months of home confinement.  Freedman Farms also is required to implement a comprehensive environmental compliance program and institute an annual training program.   In an order issued on April 19, 2012, the court ordered that the defendants would be responsible for restitution of $1 million in the form of five annual payments starting in January 2013, which the court will direct to the North Carolina Coastal Land Trust (NCCLT).  The NCCLT plans to use the money to acquire and conserve land along streams in the Waccamaw watershed.  The court also directed a $75,000 community service payment to the Southern Environmental Enforcement Network, an organization dedicated to environmental law enforcement training and information sharing in the region.    “The resolution of the case against Freedman Farms demonstrates the commitment of the Department of Justice to enforcing the Clean Water Act to ensure the protection of human health and the environment,” said Assistant Attorney General Moreno.  “The court-ordered restitution in this case will conserve wetlands for the benefit of the people of North Carolina.  By enforcing the nation’s environmental laws, we will continue to ensure that concentrated animal feeding operations (CAFOs) operate without threatening our drinking water, the health of our communities and the environment.”   “This office is committed to doing our part to hold accountable those who commit crimes against our environment, which can cause serious health problems to residents and damage the environment that makes North Carolina such a beautiful place to live and visit,” said U.S. Attorney Walker.   “This case shows what we can accomplish when our SBI agents work closely with their local, state and federal partners to investigate environmental crimes and hold the polluters accountable,” said Director McLeod.  “We’ll continue our efforts to fight illegal pollution that damages our water and puts the public’s health at risk.”    “The Waccamaw is unique and wild,” said Director Herlevich of the North Carolina Coastal Land Trust. “Its watershed includes some of the most extensive cypress gum swamps in the state, and its headwaters at Lake Waccamaw contain fish that are found nowhere else on Earth.  We appreciate the trust of the court and the U. S. Attorney, and we look forward to using these funds for conservation projects in a river system that is one of our top conservation priorities.”   According to evidence presented in court, in December 2007 Freedman Farms discharged hog waste into Browder’s Branch, a tributary to the Waccamaw River that flows through the White Marsh, a large wetlands complex.  Freedman Farms, located in Columbus County, N.C., is in the business of raising hogs for market, and this particular farm had some 4,800 hogs.  The hog waste was supposed to be directed to two lagoons for treatment and disposal.  Instead, hog waste was discharged from Freedman Farms directly into Browder’s Branch.    The Clean Water Act is a federal law that makes it illegal to knowingly or negligently discharge a pollutant into a water of the United States.    The Freedman case was investigated by the U.S. Environmental Protection Agency (EPA) Criminal Investigation Division, the U.S. Army Corps of Engineers and the North Carolina State Bureau of Investigation, with assistance from the EPA Science and Ecosystem Support Division.  The case was prosecuted by Assistant U.S. Attorney J. Gaston B. Williams of the Eastern District of North Carolina and Trial Attorney Mary Dee Carraway of the Environmental Crimes Section of the Justice Department’s Environment and Natural Resources Division.   The North Carolina Coastal Land Trust is celebrating its 20th anniversary of saving special lands in eastern North Carolina. The organization has protected nearly 50,000 acres of lands with scenic, recreational, historic and ecological values. North Carolina Coastal Land Trust has saved streams and wetlands that provide clean water, forests that are havens for wildlife, working farms that provide local food and nature parks that everyone can enjoy.  More information about the Coastal Land Trust is available at www.coastallandtrust.org.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        BOSTON– A $1-million settlement has been reached for natural resource damages (NRD) at the Blackburn & Union Privileges Superfund Site in Walpole, Mass., the Departments of Justice and Interior (DOI), and the Office of the Massachusetts Attorney General announced today.                The Blackburn & Union Privileges Superfund Site includes 22 acres of contaminated land and water in Walpole. The contamination resulted from the operations of various industrial facilities dating back to the 19th century that exposed the site to asbestos, arsenic, lead and other hazardous substances.                The private parties involved in the settlement include two former owners and operators of the site, W.R. Grace & Co.– Conn. and Tyco Healthcare Group LP, as well as the current owners, BIM Investment Corp. and Shaffer Realty Nominee Trust.               From about 1915 to 1936, a predecessor of W.R. Grace manufactured asbestos brake linings and clutch linings on a large portion of the property. From 1946 to about 1983, a predecessor of Tyco Healthcare operated a cotton fabric manufacturing business, which used caustic solutions, on a portion of the property.               In a 2010 settlement with U.S. Environmental Protection Agency (EPA), the four private parties agreed to perform a remedial action to clean up the site at an estimated cost of $13 million. The consent decree lodged today resolves both state and federal NRD liability claims; it requires the parties to pay $1,094,169.56 to the state and federal natural resource trustees, the Massachusetts Executive Office of Energy and Environmental Affairs (EEA) and DOI, for injuries to ecological resources including groundwater and wetlands, which provide habitat for waterfowl and wading birds, including black ducks and great blue herons.  The trustees will use the settlement funds for natural resource restoration projects in the area.               “This settlement demonstrates our commitment to recovering damages from the parties responsible for injury to natural resources, in partnership with state trustees,” said Bruce Gelber, Acting Deputy Assistant Attorney General of the Justice Department’s Environment and Natural Resources Division.               “The citizens of Walpole have had to live with the environmental impact of this contamination for many years,” Attorney General Martha Coakley said. “We are pleased that today’s agreement will not only require the responsible parties to reimburse taxpayer dollars, but will also provide funding to begin restoring or replacing the wetland and other natural resources.”                 The consent decree was lodged in the U.S. District Court for Massachusetts.     A portion of the funds, $300,000, will be distributed to the EEA-sponsored groundwater restoration projects; $575,000 will be used for ecological restoration projects jointly sponsored by EEA and the U.S. Fish and Wildlife Service (FWS).               In addition, $125,000 will go for projects jointly sponsored by EEA and FWS that achieve both ecological and groundwater restoration; $57,491.34 will be allocated for reimbursement for the FWS’s assessment costs; and $36,678.22 will be distributed as reimbursement for the commonwealth’s assessment costs.       “This settlement provides the means for a range of projects designed to compensate the public for decades of groundwater and other ecological damage at this site.  I encourage local citizens and organizations to become engaged in the public process that will take place as we solicit, take comment on, and choose these projects in the months ahead,” said Energy and Environmental Affairs Secretary Richard K. Sullivan Jr., who serves as the Commonwealth’s Natural Resources Damages trustee.       “This settlement will help restore habitat for fish and wildlife in the Neponset River watershed,” said Tom Chapman of the FWS New England Field Office. “We look forward to working with the commonwealth and local stakeholders to implement restoration.”               “More than 100 years-worth of industrial activities at this site caused major environmental contamination to the Neponset River, nearby wetlands and to groundwater below the site,” said Commissioner Kenneth Kimmell of the Massachusetts Department of Environmental Protection (MassDEP), which will staff the Trustee Council for the Commonwealth. “We will ensure that the community and the public will be active participants in the process to use these NRD funds to restore the injured natural resources.”                Under the federal Comprehensive Environmental Response, Compensation and Liability Act, EEA and DOI, acting through the FWS, are the designated state and federal natural resource Trustees for the site. The site has been listed on the EPA’s National Priorities List since 1994.        The consent decree is subject to a public comment period and court approval. A copy of the consent decree and instructions about how to submit comments is available on www.usdoj.gov/enrd/Consent_Decrees.html  .               After the consent decree is approved, EEA and FWS will develop proposed restoration plans to use the settlement funds for restoration projects. The proposed restoration plans will also be made available to the public for review and comment.                Assistant Attorney General Matthew Brock of Massachusetts Attorney General Coakley's Environmental Protection Division handled this matter.  Attorney Jennifer Davis of MassDEP, Attorney Anna Blumkin of EEA and MassDEP’s NRD Coordinator Karen Pelto also worked on this settlement.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           WASHINGTON—A federal grand jury in Las Vegas today returned indictments against 10 Nevada-certified emissions testers for falsifying vehicle emissions test reports, the Justice Department announced.   Each defendant faces one felony Clean Air Act count for falsifying reports between November 2007 and May 2009. The number of falsifications varied by defendant, with some defendants having falsified approximately 250 records, while others falsified more than double that figure. One defendant is alleged to have falsified over 700 reports.   The individuals indicted include:     Escudero resides in Pahrump, Nev. All other individuals are from Clark County, Nev.    The 10 defendants are alleged to have engaged in a practice known as \"clean scanning\" vehicles. The scheme involved entering the Vehicle Identification Number (VIN) for a vehicle that would not pass the emissions test into the computerized system, then connecting a different vehicle the testers knew would pass the test. These falsifications were allegedly performed for anywhere from $10 to $100 over and above the usual emissions testing fee.    The U.S. Environmental Protection Agency (EPA), under the Clean Air Act, requires the state of Nevada to conduct vehicle emissions testing in certain areas because the areas exceed national standards for carbon monoxide and ozone. Las Vegas is currently required to perform emissions testing.    To obtain a registration renewal, vehicle owners bring the vehicles to a licensed inspection station for testing. The emissions inspector logs into a computer to activate the system by using a unique password issued to the emissions inspector. The emissions inspector manually inputs the vehicle’s VIN to identify the tested vehicle, then connects the vehicle for model year 1996 and later to an onboard diagnostics port connected to an analyzer. The analyzer downloads data from the vehicle’s computer, analyzes the data and provides a \"pass\" or \"fail\" result. The pass or fail result and vehicle identification data are reported on the Vehicle Inspection Report. It is a crime to knowingly alter or conceal any record or other document required to be maintained by the Clean Air Act.     \"Falsifications of vehicle emissions testing, such as those alleged in the indictments unsealed today, are serious matters and we intend to use all of our enforcement tools to stop this harmful practice. These actions undermine a system that is designed to reduce air pollutants including smog and provide better air quality for the citizens of Nevada,\" said Ignacia S. Moreno, Assistant Attorney General for the Justice Department’s Environment and Natural Resources Division.    \"The residents of Nevada deserve to know that the vast majority of licensed vehicle emission inspectors are not corrupt and are not circumventing emission testing procedures,\" said U.S. Attorney Bogden. \"These indictments should serve as a clear warning to offenders that the Department of Justice will prosecute you if you make fraudulent statements and reports concerning compliance with the federal Clean Air Act.\"    \"Lying about car emissions means dirtier air, which is especially of concern in areas like Las Vegas that are already experiencing air quality problems,\" said Cynthia Giles, Assistant Administrator for Enforcement and Compliance Assurance at EPA. \"We will take aggressive action to ensure communities have clean air.\"    The maximum penalty for the felony violations contained in the indictments includes up to two years in prison and a fine of up to $250,000.    An indictment is merely an accusation, and a defendant is presumed innocent unless and until proven guilty in a court of law.    The case was investigated by the EPA, Criminal Investigation Division; and the Nevada Department of Motor Vehicles Compliance Enforcement Division. The case is being prosecuted by the U.S. Attorney’s Office for the District of Nevada and the Justice Department’s Environmental Crimes Section.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The U.S. Department of Justice, the U.S. Environmental Protection Agency (EPA), and the Rhode Island Department of Environmental Management (RIDEM) announced today that two subsidiaries of Stanley Black & Decker Inc.—Emhart Industries Inc. and Black & Decker Inc.—have agreed to clean up dioxin contaminated sediment and soil at the Centredale Manor Restoration Project Superfund Site in North Providence and Johnston, Rhode Island.  “We are pleased to reach a resolution through collaborative work with the responsible parties, EPA, and other stakeholders,” said Acting Assistant Attorney General Jeffrey H. Wood for the Justice Department's Environment and Natural Resources Division . “Today’s settlement ends protracted litigation and allows for important work to get underway to restore a healthy environment for citizens living in and around the Centredale Manor Site and the Woonasquatucket River.” “This settlement demonstrates the tremendous progress we are achieving working with responsible parties, states, and our federal partners to expedite sites through the entire Superfund remediation process,” said EPA Acting Administrator Andrew Wheeler. “The Centredale Manor Site has been on the National Priorities List for 18 years; we are taking charge and ensuring the Agency makes good on its promise to clean it up for the betterment of the environment and those communities affected.” “Successfully concluding this settlement paves the way for EPA to make good on our commitment to aggressively pursue cleaning up the Centredale Manor Superfund Site,” said EPA New England Regional Administrator Alexandra Dunn. “We are excited to get to work on the cleanup at this site, and get it closer to the goal of being fully utilized by the North Providence and Johnston communities.” “We are pleased that the collective efforts of the State of Rhode Island, EPA, and DOJ in these negotiations have concluded in this major milestone toward the cleanup of the Centredale Manor Restoration Superfund site and are consistent with our long-standing efforts to make the polluter pay,” said RIDEM Director Janet Coit. “The settlement will speed up a remedy that protects public health and the river environment, and moves us closer to the day that we can reclaim recreational uses of this beautiful river resource.” The settlement, which includes cleanup work in the Woonasquatucket River (River) and bordering residential and commercial properties along the River, requires the companies to perform the remedy selected by EPA for the Site in 2012, which is estimated to cost approximately $100 million, and resolves longstanding litigation. The cleanup remedy includes excavation of contaminated sediment and floodplain soil from the Woonasquatucket River, including from adjacent residential properties. Once the cleanup remedy is completed, full access to the Woonasquatucket River should be restored for local citizens. The cleanup will be a step toward the State’s goal of a fishable and swimmable river. The work will also include upgrading caps over contaminated soil in the peninsula area of the Site that currently house two high-rise apartment buildings. The settlement also ensures that the long-term monitoring and maintenance of the site, as directed in the remedy, will be implemented to ensure that public health is protected.  Under the settlement, Emhart and Black & Decker will reimburse EPA for approximately $42 million in past costs incurred at the Site. The companies will also reimburse EPA and the State of Rhode Island for future costs incurred by those agencies in overseeing the work required by the settlement. The settlement will also include payments on behalf of two federal agencies to resolve claims against those agencies. These payments, along with prior settlements related to the Site, will result in a 100 percent recovery for the United States of its past and future response costs related to the Site. Litigation related to the Site has been ongoing for nearly eight years. While the Federal District Court found Black & Decker and Emhart to be liable for their hazardous waste and responsible to conduct the cleanup of the Site, it had also ruled that EPA needed to reconsider certain aspects of that cleanup. EPA appealed the decision requiring it to reconsider aspects of the cleanup. This settlement, once entered by the District Court, will resolve the litigation between the United States, Rhode Island, and Emhart and Black and Decker, allowing the cleanup of the Site to begin. The Site spans a one and a half mile stretch of the Woonasquatucket River and encompasses a nine-acre peninsula, two ponds and a significant forested wetland. From the 1940s to the early 1970s, Emhart’s predecessor operated a chemical manufacturing facility on the peninsula and used a raw material that was contaminated with 2,3,7,8-tetrachlorodibenzo-p-dioxin, a toxic form of dioxin. The Site property was also previously used by a barrel refurbisher. Elevated levels of dioxins and other contaminants have been detected in soil, groundwater, sediment, surface water and fish.  The Site was added to the National Priorities List (NPL) in 2000, and in December 2017, EPA included the Centredale Manor Restoration Project Superfund Site on a list of Superfund sites targeted for immediate and intense attention. Several short-term actions were previously performed at the Site to address immediate threats to the residents and minimize potential erosion and downstream transport of contaminated soil and sediment. This settlement is the latest agreement EPA has reached since the Site was listed on the NPL. Prior agreements addressed the performance and recovery of costs for the past environmental investigations and interim cleanup actions from Emhart, the barrel reconditioning company, the current owners of the peninsula portion of the Site, and other potentially responsible parties. The Consent Decree, lodged in the U.S. District Court of Rhode Island, will be posted in the Federal Register and available for public comment for a period of 30 days. The Consent Decree can be viewed on the Justice Department website: www.justice.gov/enrd/Consent_Decrees.html.  EPA information on the Centredale Manor Superfund Site: www.epa.gov/superfund/centredale.   \n",
       "\n",
       "                        date topics_clean  \\\n",
       "0  2014-10-01T00:00:00-04:00     No topic   \n",
       "1  2012-07-25T00:00:00-04:00     No topic   \n",
       "2  2011-08-03T00:00:00-04:00     No topic   \n",
       "3  2010-01-08T00:00:00-05:00     No topic   \n",
       "4  2018-07-09T00:00:00-04:00  Environment   \n",
       "\n",
       "                             components_clean  \n",
       "0            National Security Division (NSD)  \n",
       "1  Environment and Natural Resources Division  \n",
       "2  Environment and Natural Resources Division  \n",
       "3  Environment and Natural Resources Division  \n",
       "4  Environment and Natural Resources Division  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## first, unzip the file pset3_inputdata.zip \n",
    "## then, run this code to load the unzipped json file and convert to a dataframe\n",
    "## (may need to change the pathname depending on where you store stuff)\n",
    "## and convert some of the attributes from lists to values\n",
    "doj = pd.read_json(\"combined.json\", lines = True)\n",
    "\n",
    "## due to json, topics are in a list so remove them and concatenate with ;\n",
    "doj['topics_clean'] = [\"; \".join(topic) \n",
    "                      if len(topic) > 0 else \"No topic\" \n",
    "                      for topic in doj.topics]\n",
    "\n",
    "## similarly with components\n",
    "doj['components_clean'] = [\"; \".join(comp) \n",
    "                           if len(comp) > 0 else \"No component\" \n",
    "                           for comp in doj.components]\n",
    "\n",
    "## drop older columns from data\n",
    "doj = doj[['id', 'title', 'contents', 'date', 'topics_clean', \n",
    "           'components_clean']].copy()\n",
    "\n",
    "doj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tagging and sentiment scoring (17 points)\n",
    "\n",
    "Focus on the following press release: `id` == \"17-1204\" about this pharmaceutical kickback prosecution: https://www.forbes.com/sites/michelatindera/2017/11/16/fentanyl-billionaire-john-kapoor-to-plead-not-guilty-in-opioid-kickback-case/?sh=21b8574d6c6c \n",
    "\n",
    "The `contents` column is the one we're treating as a document. You may need to to convert it from a pandas series to a single string.\n",
    "\n",
    "We'll call the raw string of this press release `pharma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The founder and majority owner of Insys Therapeutics Inc., was arrested today and charged with leading a nationwide conspiracy to profit by using bribes and fraud to cause the illegal distribution of a Fentanyl spray intended for cancer patients experiencing breakthrough pain.\\xa0\"More than 20,000 Americans died of synthetic opioid overdoses last year, and millions are addicted to opioids. And yet some medical professionals would rather take advantage of the addicts than try to help them,\" said Attorney General Jeff Sessions. \"This Justice Department will not tolerate this.\\xa0 We will hold accountable anyone – from street dealers to corporate executives -- who illegally contributes to this nationwide epidemic.\\xa0 And under the leadership of President Trump, we are fully committed to defeating this threat to the American people.”John N. Kapoor, 74, of Phoenix, Ariz., a current member of the Board of Directors of Insys, was arrested this morning in Arizona and charged with RICO conspiracy, as well as other felonies, including conspiracy to commit mail and wire fraud and conspiracy to violate the Anti-Kickback Law. Kapoor, the former Executive Chairman of the Board and CEO of Insys, will appear in federal court in Phoenix today.\\xa0 He will appear in U.S. District Court in Boston at a later date.\\xa0The superseding indictment, unsealed today in Boston, also includes additional allegations against several former Insys executives and managers who were initially indicted in December 2016.The superseding indictment charges that Kapoor; Michael L. Babich, 40, of Scottsdale, Ariz., former CEO and President of the company; Alec Burlakoff, 42, of Charlotte, N.C., former Vice President of Sales; Richard M. Simon, 46, of Seal Beach, Calif., former National Director of Sales; former Regional Sales Directors Sunrise Lee, 36, of Bryant City, Mich., and Joseph A. Rowan, 43, of Panama City, Fla.; and former Vice President of Managed Markets, Michael J. Gurry, 53, of Scottsdale, Ariz., conspired to bribe practitioners in various states, many of whom operated pain clinics, in order to get them to prescribe a fentanyl-based pain medication.\\xa0 The medication, called “Subsys,” is a powerful narcotic intended to treat cancer patients suffering intense breakthrough pain.\\xa0 In exchange for bribes and kickbacks, the practitioners wrote large numbers of prescriptions for the patients, most of whom were not diagnosed with cancer.The indictment also alleges that Kapoor and the six former executives conspired to mislead and defraud health insurance providers who were reluctant to approve payment for the drug when it was prescribed for non-cancer patients.\\xa0 They achieved this goal by setting up the “reimbursement unit,” which was dedicated to obtaining prior authorization directly from insurers and pharmacy benefit managers.\\xa0“In the midst of a nationwide opioid epidemic that has reached crisis proportions, Mr. Kapoor and his company stand accused of bribing doctors to overprescribe a potent opioid and committing fraud on insurance companies solely for profit,” said Acting United States Attorney William D. Weinreb. “Today\\'s arrest and charges reflect our ongoing efforts to attack the opioid crisis from all angles. We must hold the industry and its leadership accountable - just as we would the cartels or a street-level drug dealer.”“As alleged, these executives created a corporate culture at Insys that utilized deception and bribery as an acceptable business practice, deceiving patients, and conspiring with doctors and insurers,” said Harold H. Shaw, Special Agent in Charge of the Federal Bureau of Investigation, Boston Field Division. “The allegations of selling a highly addictive opioid cancer pain drug to patients who did not have cancer, make them no better than street-level drug dealers. Today\\'s charges mark an important step in holding pharmaceutical executives responsible for their part in the opioid crisis.\\xa0\\xa0 The FBI will vigorously investigate corrupt organizations with business practices that promote fraud with a total disregard for patient safety.”“These Insys executives allegedly fueled the opioid epidemic by paying doctors to needlessly prescribe an extremely dangerous and addictive form of fentanyl,” said Phillip Coyne, Special Agent in Charge for the Office of Inspector General of the U.S. Department of Health and Human Services.\\xa0 “Corporate executives intent on illegally driving up profits need to be aware they are now squarely in the sights of law enforcement.”“As alleged, Insys executives improperly influenced health care providers to prescribe a powerful opioid for patients who did not need it, and without complying with FDA requirements, thus putting patients at risk and contributing to the current opioid crisis,” said Mark A. McCormack, Special Agent in Charge, FDA Office of Criminal Investigations’ Metro Washington Field Office. “Our office will continue to work with our law enforcement partners to pursue and bring to justice those who threaten the public health.”“Pharmaceutical companies whose products include controlled medications that can lead to addiction and overdose have a special obligation to operate in a trustworthy, transparent manner, because their customers’ health and safety and, indeed, very lives depend on it,” said DEA Special Agent in Charge Michael J. Ferguson.\\xa0 “DEA pledges to work with our law enforcement and regulatory partners nationwide to ensure that rules and regulations under the Controlled Substances Act are followed.”“Today’s arrest is the result of a joint effort to identify, investigate and prosecute individuals who engage in fraudulent activity and endanger patient health,” stated Special Agent in Charge Leigh-Alistair Barzey, Defense Criminal Investigative Service (DCIS) Northeast Field Office.\\xa0 “DCIS will continue to work with the U.S. Attorney’s Office, District of Massachusetts, and our law enforcement partners, to protect U.S. military members, retirees and their dependents and the integrity of TRICARE, the Defense Department’s healthcare system.”“As alleged, John Kapoor and other top executives committed fraud, placing profit before patient safety, to sell a highly potent and addictive opioid.\\xa0 EBSA will take every opportunity to work collaboratively with our law enforcement partners in these important investigations to protect participants in private sector health plans and contribute in fighting the opioid epidemic,” said Susan A. Hensley, Regional Director of the U.S. Department of Labor, Employee Benefits Security Administration, Boston Regional Office.“Once again, the United States Postal Inspection Service is fully committed to protecting our nation’s mail system from criminal misuse,” said Shelly Binkowski, Inspector in Charge of the U.S. Postal Inspection Service. “We are proud to work alongside our law enforcement partners to dismantle high level prescription drug practices which directly contribute to the opioid abuse epidemic.\\xa0 This investigation highlights our commitment to defending our mail system from illegal misuse and ensuring public trust in the mail.”“The U.S. Department of Veterans Affairs, Office of Inspector General will continue to aggressively investigate those that attempt to fraudulently impact programs designed to benefit our veterans and their families,” said Donna L. Neves, Special Agent in Charge of the VA OIG Northeast Field Office.The charges of conspiracy to commit RICO and conspiracy to commit mail and wire fraud each provide for a sentence of no greater than 20 years in prison, three years of supervised release and a fine of $250,000, or twice the amount of pecuniary gain or loss.\\xa0 The charges of conspiracy to violate the Anti-Kickback Law provide for a sentence of no greater than five years in prison, three years of supervised release and a $25,000 fine. Sentences are imposed by a federal district court judge based upon the U.S. Sentencing Guidelines and other statutory factors.The investigation was conducted by a team that included the FBI; HHS-OIG; FDA Office of Criminal Investigations; the Defense Criminal Investigative Service; the Drug Enforcement Administration; the Department of Labor, Employee Benefits Security Administration; the Office of Personnel Management; the U.S. Postal Inspection Service; the U.S. Postal Service Office of Inspector General; and the Department of Veterans Affairs.\\xa0 The U.S. Attorney’s Office would like to acknowledge the cooperation and assistance of the U.S. Attorney’s Offices around the country engaged in parallel investigations, including the District of Connecticut, Eastern District of Michigan, Southern District of Alabama, Southern District of New York, District of Rhode Island, and the District of New Hampshire.\\xa0 The efforts of the Central District of California and the Justice Department’s Civil Fraud Section of the Department of Justice are also greatly appreciated.\\xa0Assistant U.S. Attorneys K. Nathaniel Yeager, Chief of Weinreb’s Health Care Fraud Unit, and Susan M. Poswistilo, of Weinreb’s Civil Division, are prosecuting the case.The details contained in the charging documents are allegations.\\xa0 The defendants are presumed innocent unless and until proven guilty beyond a reasonable doubt.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code to subset to one press release and take the string\n",
    "\n",
    "pharma_release = doj[doj['id'] == \"17-1204\"]\n",
    "\n",
    "# Extract the contents of the press release\n",
    "pharma_contents = pharma_release['contents'].iloc[0]\n",
    "\n",
    "pharma_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 part of speech tagging (3 points)\n",
    "\n",
    "A. Preprocess the `pharma` press release to remove all punctuation / digits (you can use `.isalpha()` to subset)\n",
    "\n",
    "B. With the preprocessed press release from part A, use the part of speech tagger within nltk to tag all the words in that one press release with their part of speech. \n",
    "\n",
    "C. Using the output from B, extract the adjectives and sort those adjectives from most occurrences to fewest occurrences. Print a dataframe with the 5 most frequent adjectives and their counts in the `pharma` release. See here for a list of the names of adjectives within nltk: https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Documentation for `.isalpha()`: https://www.w3schools.com/python/ref_string_isalpha.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to restrict to alpha\n",
    "\n",
    "pharma_preprocessed = ''.join(char for char in pharma_contents if char.isalpha() or char.isspace())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('founder', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('majority', 'NN'),\n",
       " ('owner', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Insys', 'NNP'),\n",
       " ('Therapeutics', 'NNP'),\n",
       " ('Inc', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('arrested', 'VBN'),\n",
       " ('today', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('charged', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('leading', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('nationwide', 'JJ'),\n",
       " ('conspiracy', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('profit', 'VB'),\n",
       " ('by', 'IN'),\n",
       " ('using', 'VBG'),\n",
       " ('bribes', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('fraud', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('cause', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('illegal', 'JJ'),\n",
       " ('distribution', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('Fentanyl', 'NNP'),\n",
       " ('spray', 'NN'),\n",
       " ('intended', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('cancer', 'NN'),\n",
       " ('patients', 'NNS'),\n",
       " ('experiencing', 'VBG'),\n",
       " ('breakthrough', 'NN'),\n",
       " ('pain', 'NN'),\n",
       " ('More', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('Americans', 'NNPS'),\n",
       " ('died', 'VBD'),\n",
       " ('of', 'IN'),\n",
       " ('synthetic', 'JJ'),\n",
       " ('opioid', 'NN'),\n",
       " ('overdoses', 'NNS'),\n",
       " ('last', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('millions', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('addicted', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('opioids', 'NNS'),\n",
       " ('And', 'CC'),\n",
       " ('yet', 'RB'),\n",
       " ('some', 'DT'),\n",
       " ('medical', 'JJ'),\n",
       " ('professionals', 'NNS'),\n",
       " ('would', 'MD'),\n",
       " ('rather', 'RB'),\n",
       " ('take', 'VB'),\n",
       " ('advantage', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('addicts', 'NNS'),\n",
       " ('than', 'IN'),\n",
       " ('try', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('help', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('Attorney', 'NNP'),\n",
       " ('General', 'NNP'),\n",
       " ('Jeff', 'NNP'),\n",
       " ('Sessions', 'NNP'),\n",
       " ('This', 'DT'),\n",
       " ('Justice', 'NNP'),\n",
       " ('Department', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('tolerate', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('We', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('hold', 'VB'),\n",
       " ('accountable', 'JJ'),\n",
       " ('anyone', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('street', 'NN'),\n",
       " ('dealers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('corporate', 'JJ'),\n",
       " ('executives', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('illegally', 'RB'),\n",
       " ('contributes', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('this', 'DT'),\n",
       " ('nationwide', 'JJ'),\n",
       " ('epidemic', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('under', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('leadership', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('President', 'NNP'),\n",
       " ('Trump', 'NNP'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('fully', 'RB'),\n",
       " ('committed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('defeating', 'VBG'),\n",
       " ('this', 'DT'),\n",
       " ('threat', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('American', 'NNP'),\n",
       " ('peopleJohn', 'NN'),\n",
       " ('N', 'NNP'),\n",
       " ('Kapoor', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Phoenix', 'NNP'),\n",
       " ('Ariz', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('current', 'JJ'),\n",
       " ('member', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Board', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Directors', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Insys', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('arrested', 'VBN'),\n",
       " ('this', 'DT'),\n",
       " ('morning', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Arizona', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('charged', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('RICO', 'NNP'),\n",
       " ('conspiracy', 'NN'),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('other', 'JJ'),\n",
       " ('felonies', 'NNS'),\n",
       " ('including', 'VBG'),\n",
       " ('conspiracy', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('commit', 'VB'),\n",
       " ('mail', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('wire', 'NN'),\n",
       " ('fraud', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('conspiracy', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('violate', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('AntiKickback', 'NNP'),\n",
       " ('Law', 'NNP'),\n",
       " ('Kapoor', 'NNP'),\n",
       " ('the', 'DT'),\n",
       " ('former', 'JJ'),\n",
       " ('Executive', 'NNP'),\n",
       " ('Chairman', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Board', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('CEO', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Insys', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('appear', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('federal', 'JJ'),\n",
       " ('court', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Phoenix', 'NNP'),\n",
       " ('today', 'NN'),\n",
       " ('He', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('appear', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('US', 'NNP'),\n",
       " ('District', 'NNP'),\n",
       " ('Court', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Boston', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('later', 'JJ'),\n",
       " ('date', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('superseding', 'NN'),\n",
       " ('indictment', 'NN'),\n",
       " ('unsealed', 'VBD'),\n",
       " ('today', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Boston', 'NNP'),\n",
       " ('also', 'RB'),\n",
       " ('includes', 'VBZ'),\n",
       " ('additional', 'JJ'),\n",
       " ('allegations', 'NNS'),\n",
       " ('against', 'IN'),\n",
       " ('several', 'JJ'),\n",
       " ('former', 'JJ'),\n",
       " ('Insys', 'NNP'),\n",
       " ('executives', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('managers', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('were', 'VBD'),\n",
       " ('initially', 'RB'),\n",
       " ('indicted', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('December', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('superseding', 'NN'),\n",
       " ('indictment', 'NN'),\n",
       " ('charges', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('Kapoor', 'NNP'),\n",
       " ('Michael', 'NNP'),\n",
       " ('L', 'NNP'),\n",
       " ('Babich', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Scottsdale', 'NNP'),\n",
       " ('Ariz', 'NNP'),\n",
       " ('former', 'JJ'),\n",
       " ('CEO', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('President', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('Alec', 'NNP'),\n",
       " ('Burlakoff', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Charlotte', 'NNP'),\n",
       " ('NC', 'NNP'),\n",
       " ('former', 'JJ'),\n",
       " ('Vice', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Sales', 'NNS'),\n",
       " ('Richard', 'NNP'),\n",
       " ('M', 'NNP'),\n",
       " ('Simon', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Seal', 'NNP'),\n",
       " ('Beach', 'NNP'),\n",
       " ('Calif', 'NNP'),\n",
       " ('former', 'JJ'),\n",
       " ('National', 'NNP'),\n",
       " ('Director', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Sales', 'NNS'),\n",
       " ('former', 'JJ'),\n",
       " ('Regional', 'NNP'),\n",
       " ('Sales', 'NNS'),\n",
       " ('Directors', 'NNP'),\n",
       " ('Sunrise', 'NNP'),\n",
       " ('Lee', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Bryant', 'NNP'),\n",
       " ('City', 'NNP'),\n",
       " ('Mich', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Joseph', 'NNP'),\n",
       " ('A', 'NNP'),\n",
       " ('Rowan', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Panama', 'NNP'),\n",
       " ('City', 'NNP'),\n",
       " ('Fla', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('former', 'JJ'),\n",
       " ('Vice', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Managed', 'NNP'),\n",
       " ('Markets', 'NNP'),\n",
       " ('Michael', 'NNP'),\n",
       " ('J', 'NNP'),\n",
       " ('Gurry', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Scottsdale', 'NNP'),\n",
       " ('Ariz', 'NNP'),\n",
       " ('conspired', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('bribe', 'VB'),\n",
       " ('practitioners', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('various', 'JJ'),\n",
       " ('states', 'NNS'),\n",
       " ('many', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('whom', 'WP'),\n",
       " ('operated', 'VBD'),\n",
       " ('pain', 'NN'),\n",
       " ('clinics', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('order', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('prescribe', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('fentanylbased', 'JJ'),\n",
       " ('pain', 'NN'),\n",
       " ('medication', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('medication', 'NN'),\n",
       " ('called', 'VBN'),\n",
       " ('Subsys', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('powerful', 'JJ'),\n",
       " ('narcotic', 'JJ'),\n",
       " ('intended', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('treat', 'VB'),\n",
       " ('cancer', 'NN'),\n",
       " ('patients', 'NNS'),\n",
       " ('suffering', 'VBG'),\n",
       " ('intense', 'JJ'),\n",
       " ('breakthrough', 'NN'),\n",
       " ('pain', 'NN'),\n",
       " ('In', 'IN'),\n",
       " ('exchange', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('bribes', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('kickbacks', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('practitioners', 'NNS'),\n",
       " ('wrote', 'VBD'),\n",
       " ('large', 'JJ'),\n",
       " ('numbers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('prescriptions', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('patients', 'NNS'),\n",
       " ('most', 'JJS'),\n",
       " ('of', 'IN'),\n",
       " ('whom', 'WP'),\n",
       " ('were', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('diagnosed', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('cancerThe', 'NN'),\n",
       " ('indictment', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('alleges', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('Kapoor', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('six', 'CD'),\n",
       " ('former', 'JJ'),\n",
       " ('executives', 'NNS'),\n",
       " ('conspired', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('mislead', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('defraud', 'VB'),\n",
       " ('health', 'NN'),\n",
       " ('insurance', 'NN'),\n",
       " ('providers', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('were', 'VBD'),\n",
       " ('reluctant', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('approve', 'VB'),\n",
       " ('payment', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('drug', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('prescribed', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('noncancer', 'NN'),\n",
       " ('patients', 'NNS'),\n",
       " ('They', 'PRP'),\n",
       " ('achieved', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('goal', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('setting', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('reimbursement', 'NN'),\n",
       " ('unit', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('was', 'VBD'),\n",
       " ('dedicated', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('obtaining', 'VBG'),\n",
       " ('prior', 'JJ'),\n",
       " ('authorization', 'NN'),\n",
       " ('directly', 'RB'),\n",
       " ('from', 'IN'),\n",
       " ('insurers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('pharmacy', 'NN'),\n",
       " ('benefit', 'NN'),\n",
       " ('managers', 'NNS'),\n",
       " ('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('midst', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nationwide', 'JJ'),\n",
       " ('opioid', 'NN'),\n",
       " ('epidemic', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('has', 'VBZ'),\n",
       " ('reached', 'VBN'),\n",
       " ('crisis', 'NN'),\n",
       " ('proportions', 'NNS'),\n",
       " ('Mr', 'NNP'),\n",
       " ('Kapoor', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('his', 'PRP$'),\n",
       " ('company', 'NN'),\n",
       " ('stand', 'VBP'),\n",
       " ('accused', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('bribing', 'VBG'),\n",
       " ('doctors', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('overprescribe', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('potent', 'JJ'),\n",
       " ('opioid', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('committing', 'VBG'),\n",
       " ('fraud', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('insurance', 'NN'),\n",
       " ('companies', 'NNS'),\n",
       " ('solely', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('profit', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('Acting', 'NNP'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('Attorney', 'NNP'),\n",
       " ('William', 'NNP'),\n",
       " ('D', 'NNP'),\n",
       " ('Weinreb', 'NNP'),\n",
       " ('Todays', 'NNP'),\n",
       " ('arrest', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('charges', 'NNS'),\n",
       " ('reflect', 'VBP'),\n",
       " ('our', 'PRP$'),\n",
       " ('ongoing', 'JJ'),\n",
       " ('efforts', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('attack', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('opioid', 'JJ'),\n",
       " ('crisis', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('angles', 'NNS'),\n",
       " ('We', 'PRP'),\n",
       " ('must', 'MD'),\n",
       " ('hold', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('industry', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('its', 'PRP$'),\n",
       " ('leadership', 'NN'),\n",
       " ('accountable', 'JJ'),\n",
       " ('just', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('the', 'DT'),\n",
       " ('cartels', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('streetlevel', 'JJ'),\n",
       " ('drug', 'NN'),\n",
       " ('dealerAs', 'NNS'),\n",
       " ('alleged', 'VBN'),\n",
       " ('these', 'DT'),\n",
       " ('executives', 'NNS'),\n",
       " ('created', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('corporate', 'JJ'),\n",
       " ('culture', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('Insys', 'NNP'),\n",
       " ('that', 'WDT'),\n",
       " ('utilized', 'JJ'),\n",
       " ('deception', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('bribery', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('acceptable', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " ('practice', 'NN'),\n",
       " ('deceiving', 'VBG'),\n",
       " ('patients', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('conspiring', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('doctors', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('insurers', 'NNS'),\n",
       " ('said', 'VBD'),\n",
       " ('Harold', 'NNP'),\n",
       " ('H', 'NNP'),\n",
       " ('Shaw', 'NNP'),\n",
       " ('Special', 'NNP'),\n",
       " ('Agent', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Charge', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Federal', 'NNP'),\n",
       " ('Bureau', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Investigation', 'NNP'),\n",
       " ('Boston', 'NNP'),\n",
       " ('Field', 'NNP'),\n",
       " ('Division', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('allegations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('selling', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('highly', 'RB'),\n",
       " ('addictive', 'JJ'),\n",
       " ('opioid', 'NN'),\n",
       " ('cancer', 'NN'),\n",
       " ('pain', 'VBP'),\n",
       " ('drug', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('patients', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('cancer', 'NN'),\n",
       " ('make', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('no', 'DT'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('streetlevel', 'JJ'),\n",
       " ('drug', 'NN'),\n",
       " ('dealers', 'NNS'),\n",
       " ('Todays', 'VBP'),\n",
       " ('charges', 'NNS'),\n",
       " ('mark', 'VBP'),\n",
       " ('an', 'DT'),\n",
       " ('important', 'JJ'),\n",
       " ('step', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('holding', 'VBG'),\n",
       " ('pharmaceutical', 'JJ'),\n",
       " ('executives', 'NNS'),\n",
       " ('responsible', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('part', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('opioid', 'JJ'),\n",
       " ('crisis', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('FBI', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('vigorously', 'RB'),\n",
       " ('investigate', 'VB'),\n",
       " ('corrupt', 'JJ'),\n",
       " ('organizations', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('business', 'NN'),\n",
       " ('practices', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('promote', 'VBP'),\n",
       " ('fraud', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('total', 'JJ'),\n",
       " ('disregard', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('patient', 'JJ'),\n",
       " ('safetyThese', 'JJ'),\n",
       " ('Insys', 'NNP'),\n",
       " ('executives', 'NNS'),\n",
       " ('allegedly', 'RB'),\n",
       " ('fueled', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('opioid', 'JJ'),\n",
       " ('epidemic', 'JJ'),\n",
       " ('by', 'IN'),\n",
       " ('paying', 'VBG'),\n",
       " ('doctors', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('needlessly', 'RB'),\n",
       " ('prescribe', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('extremely', 'RB'),\n",
       " ('dangerous', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('addictive', 'JJ'),\n",
       " ('form', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('fentanyl', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('Phillip', 'NNP'),\n",
       " ('Coyne', 'NNP'),\n",
       " ('Special', 'NNP'),\n",
       " ('Agent', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Charge', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Office', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Inspector', 'NNP'),\n",
       " ('General', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('Department', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Health', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Human', 'NNP'),\n",
       " ('Services', 'NNPS'),\n",
       " ('Corporate', 'NNP'),\n",
       " ('executives', 'NNS'),\n",
       " ('intent', 'VBP'),\n",
       " ('on', 'IN'),\n",
       " ('illegally', 'RB'),\n",
       " ('driving', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('profits', 'NNS'),\n",
       " ('need', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('aware', 'JJ'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('now', 'RB'),\n",
       " ('squarely', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('sights', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('law', 'NN'),\n",
       " ('enforcementAs', 'NN'),\n",
       " ('alleged', 'VBD'),\n",
       " ('Insys', 'NNP'),\n",
       " ('executives', 'NNS'),\n",
       " ('improperly', 'RB'),\n",
       " ('influenced', 'VBD'),\n",
       " ('health', 'NN'),\n",
       " ('care', 'NN'),\n",
       " ('providers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('prescribe', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('powerful', 'JJ'),\n",
       " ('opioid', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('patients', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('need', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('without', 'IN'),\n",
       " ('complying', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('FDA', 'NNP'),\n",
       " ('requirements', 'NNS'),\n",
       " ('thus', 'RB'),\n",
       " ('putting', 'VBG'),\n",
       " ('patients', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('risk', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('contributing', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('current', 'JJ'),\n",
       " ('opioid', 'NN'),\n",
       " ('crisis', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('Mark', 'NNP'),\n",
       " ('A', 'NNP'),\n",
       " ('McCormack', 'NNP'),\n",
       " ('Special', 'NNP'),\n",
       " ('Agent', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Charge', 'NNP'),\n",
       " ('FDA', 'NNP'),\n",
       " ('Office', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Criminal', 'NNP'),\n",
       " ('Investigations', 'NNP'),\n",
       " ('Metro', 'NNP'),\n",
       " ('Washington', 'NNP'),\n",
       " ('Field', 'NNP'),\n",
       " ('Office', 'NNP'),\n",
       " ('Our', 'PRP$'),\n",
       " ('office', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('continue', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('work', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('law', 'NN'),\n",
       " ('enforcement', 'NN'),\n",
       " ('partners', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('pursue', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('bring', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('justice', 'VB'),\n",
       " ('those', 'DT'),\n",
       " ('who', 'WP'),\n",
       " ('threaten', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('public', 'JJ'),\n",
       " ('healthPharmaceutical', 'JJ'),\n",
       " ('companies', 'NNS'),\n",
       " ('whose', 'WP$'),\n",
       " ('products', 'NNS'),\n",
       " ('include', 'VBP'),\n",
       " ('controlled', 'JJ'),\n",
       " ('medications', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('can', 'MD'),\n",
       " ('lead', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('addiction', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('overdose', 'RB'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('special', 'JJ'),\n",
       " ('obligation', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('operate', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('trustworthy', 'JJ'),\n",
       " ('transparent', 'NN'),\n",
       " ('manner', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('customers', 'NNS'),\n",
       " ('health', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('safety', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('indeed', 'RB'),\n",
       " ('very', 'RB'),\n",
       " ('lives', 'VBZ'),\n",
       " ('depend', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('DEA', 'NNP'),\n",
       " ('Special', 'NNP'),\n",
       " ('Agent', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Charge', 'NNP'),\n",
       " ('Michael', 'NNP'),\n",
       " ('J', 'NNP'),\n",
       " ('Ferguson', 'NNP'),\n",
       " ('DEA', 'NNP'),\n",
       " ('pledges', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('work', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('law', 'NN'),\n",
       " ('enforcement', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('regulatory', 'JJ'),\n",
       " ('partners', 'NNS'),\n",
       " ('nationwide', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('ensure', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('rules', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('regulations', 'NNS'),\n",
       " ('under', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Controlled', 'NNP'),\n",
       " ('Substances', 'NNP'),\n",
       " ('Act', 'NNP'),\n",
       " ('are', 'VBP'),\n",
       " ('followedTodays', 'JJ'),\n",
       " ('arrest', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('result', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('joint', 'JJ'),\n",
       " ('effort', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('identify', 'VB'),\n",
       " ('investigate', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('prosecute', 'JJ'),\n",
       " ('individuals', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('engage', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('fraudulent', 'JJ'),\n",
       " ('activity', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('endanger', 'NN'),\n",
       " ('patient', 'NN'),\n",
       " ('health', 'NN'),\n",
       " ('stated', 'VBN'),\n",
       " ('Special', 'JJ'),\n",
       " ('Agent', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Charge', 'NNP'),\n",
       " ('LeighAlistair', 'NNP'),\n",
       " ('Barzey', 'NNP'),\n",
       " ('Defense', 'NNP'),\n",
       " ('Criminal', 'NNP'),\n",
       " ('Investigative', 'NNP'),\n",
       " ('Service', 'NNP'),\n",
       " ('DCIS', 'NNP'),\n",
       " ('Northeast', 'NNP'),\n",
       " ('Field', 'NNP'),\n",
       " ('Office', 'NNP'),\n",
       " ('DCIS', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('continue', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('work', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('Attorneys', 'NNP'),\n",
       " ('Office', 'NNP'),\n",
       " ('District', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Massachusetts', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('our', 'PRP$'),\n",
       " ('law', 'NN'),\n",
       " ('enforcement', 'NN'),\n",
       " ('partners', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('protect', 'VB'),\n",
       " ('US', 'NNP'),\n",
       " ('military', 'JJ'),\n",
       " ('members', 'NNS'),\n",
       " ('retirees', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('their', 'PRP$'),\n",
       " ('dependents', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('integrity', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('TRICARE', 'NNP'),\n",
       " ('the', 'DT'),\n",
       " ('Defense', 'NNP'),\n",
       " ('Departments', 'NNP'),\n",
       " ('healthcare', 'NN'),\n",
       " ('systemAs', 'NN'),\n",
       " ('alleged', 'VBD'),\n",
       " ('John', 'NNP'),\n",
       " ('Kapoor', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('other', 'JJ'),\n",
       " ('top', 'JJ'),\n",
       " ('executives', 'NNS'),\n",
       " ('committed', 'VBD'),\n",
       " ('fraud', 'NN'),\n",
       " ('placing', 'NN'),\n",
       " ('profit', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('patient', 'JJ'),\n",
       " ('safety', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('sell', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('highly', 'RB'),\n",
       " ('potent', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('addictive', 'JJ'),\n",
       " ('opioid', 'NN'),\n",
       " ('EBSA', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('every', 'DT'),\n",
       " ('opportunity', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('work', 'VB'),\n",
       " ('collaboratively', 'RB'),\n",
       " ('with', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('law', 'NN'),\n",
       " ('enforcement', 'NN'),\n",
       " ('partners', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('important', 'JJ'),\n",
       " ('investigations', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('protect', 'VB'),\n",
       " ('participants', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('private', 'JJ'),\n",
       " ('sector', 'NN'),\n",
       " ('health', 'NN'),\n",
       " ('plans', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('contribute', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('fighting', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('opioid', 'JJ'),\n",
       " ('epidemic', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('Susan', 'NNP'),\n",
       " ('A', 'NNP'),\n",
       " ('Hensley', 'NNP'),\n",
       " ('Regional', 'NNP'),\n",
       " ('Director', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('Department', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Labor', 'NNP'),\n",
       " ('Employee', 'NNP'),\n",
       " ('Benefits', 'NNP'),\n",
       " ('Security', 'NNP'),\n",
       " ('Administration', 'NNP'),\n",
       " ('Boston', 'NNP'),\n",
       " ('Regional', 'NNP'),\n",
       " ('OfficeOnce', 'NNP'),\n",
       " ('again', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('Postal', 'NNP'),\n",
       " ('Inspection', 'NNP'),\n",
       " ('Service', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('fully', 'RB'),\n",
       " ('committed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('protecting', 'VBG'),\n",
       " ('our', 'PRP$'),\n",
       " ('nations', 'NNS'),\n",
       " ('mail', 'NN'),\n",
       " ('system', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('criminal', 'JJ'),\n",
       " ('misuse', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('Shelly', 'NNP'),\n",
       " ('Binkowski', 'NNP'),\n",
       " ('Inspector', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Charge', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code here for part of speech tagging\n",
    "\n",
    "tokens = word_tokenize(pharma_preprocessed) # Generate list of tokens\n",
    "tokens_pos = pos_tag(tokens) # generate part of speech tags for those tokens\n",
    "tokens_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'former': 8,\n",
       "         'opioid': 5,\n",
       "         'nationwide': 4,\n",
       "         'other': 3,\n",
       "         'addictive': 3,\n",
       "         'illegal': 2,\n",
       "         'accountable': 2,\n",
       "         'corporate': 2,\n",
       "         'current': 2,\n",
       "         'federal': 2,\n",
       "         'powerful': 2,\n",
       "         'potent': 2,\n",
       "         'streetlevel': 2,\n",
       "         'important': 2,\n",
       "         'patient': 2,\n",
       "         'public': 2,\n",
       "         'greater': 2,\n",
       "         'supervised': 2,\n",
       "         'More': 1,\n",
       "         'synthetic': 1,\n",
       "         'last': 1,\n",
       "         'medical': 1,\n",
       "         'later': 1,\n",
       "         'additional': 1,\n",
       "         'several': 1,\n",
       "         'various': 1,\n",
       "         'many': 1,\n",
       "         'fentanylbased': 1,\n",
       "         'narcotic': 1,\n",
       "         'intense': 1,\n",
       "         'large': 1,\n",
       "         'most': 1,\n",
       "         'reluctant': 1,\n",
       "         'prior': 1,\n",
       "         'ongoing': 1,\n",
       "         'utilized': 1,\n",
       "         'acceptable': 1,\n",
       "         'better': 1,\n",
       "         'pharmaceutical': 1,\n",
       "         'responsible': 1,\n",
       "         'corrupt': 1,\n",
       "         'total': 1,\n",
       "         'safetyThese': 1,\n",
       "         'epidemic': 1,\n",
       "         'dangerous': 1,\n",
       "         'aware': 1,\n",
       "         'healthPharmaceutical': 1,\n",
       "         'controlled': 1,\n",
       "         'special': 1,\n",
       "         'trustworthy': 1,\n",
       "         'regulatory': 1,\n",
       "         'followedTodays': 1,\n",
       "         'joint': 1,\n",
       "         'prosecute': 1,\n",
       "         'fraudulent': 1,\n",
       "         'Special': 1,\n",
       "         'military': 1,\n",
       "         'top': 1,\n",
       "         'private': 1,\n",
       "         'criminal': 1,\n",
       "         'proud': 1,\n",
       "         'high': 1,\n",
       "         'impact': 1,\n",
       "         'pecuniary': 1,\n",
       "         'fine': 1,\n",
       "         'statutory': 1,\n",
       "         'factorsThe': 1,\n",
       "         'parallel': 1,\n",
       "         'innocent': 1,\n",
       "         'guilty': 1,\n",
       "         'reasonable': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All adjectives\n",
    "all_adjectives = [one_tok[0] for one_tok in tokens_pos \n",
    "                if one_tok[1] == \"JJS\" or \n",
    "               one_tok[1] == \"JJR\" or\n",
    "               one_tok[1] == \"JJ\"]\n",
    "\n",
    "adjectives_count = Counter(all_adjectives)\n",
    "\n",
    "adjectives_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Adjective  Count\n",
      "10      former      8\n",
      "27      opioid      5\n",
      "0   nationwide      4\n",
      "31   addictive      3\n",
      "9        other      3\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the adjectives and their counts\n",
    "adjectives_df = pd.DataFrame(adjectives_count.items(), columns=['Adjective', 'Count'])\n",
    "\n",
    "# Sort adjectives by count in descending order\n",
    "adjectives_df = adjectives_df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Print the top 5 most frequent adjectives\n",
    "print(adjectives_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 named entity recognition (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Using the original `pharma` press release (so the one before stripping punctuation/digits), use spaCy to extract all named entities from the press release.\n",
    "\n",
    "B. Print the unique named entities with the tag: `LAW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharma_nlp = nlp(pharma_contents)\n",
    "# loop over the doc object\n",
    "named_entities = [ent.text for ent in pharma_nlp.ents]\n",
    "\n",
    "#extract unique named entities with the tag \"LAW\"\n",
    "unique_law_entities = set([ent.text for ent in pharma_nlp.ents if ent.label_ == \"LAW\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Use Google to summarize in one sentence what the `RICO` named entity means and why this might apply to a pharmaceutical kickbacks case (and not just a mafia case...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pharmaceutical companies may be subject to investigations and legal actions under the Racketeer Influenced and Corrupt Organizations Act (RICO) if they are alleged to have participated in activities that breach this law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. You want to extract the possible sentence lengths the CEO is facing; pull out the named entities with (1) the label `DATE` and (2) that contain the word year or years (hint: you may want to use the `re` module for that second part). Print these named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last year', '20 years', 'three years', 'five years', 'three years']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the named entities with the pos tag DATE\n",
    "date_entities = [ent.text for ent in pharma_nlp.ents if ent.label_ == \"DATE\" and re.search(r'\\b(?:year|years)\\b', ent.text, re.I)]\n",
    "date_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Pull and print the original parts of the press releases where those year lengths are mentioned (e.g., the sentences or rough region of the press release). Describe in your own words (1 sentence) what length of sentence (prison) and probation (supervised release) the CEO may be facing if convicted after this indictment (if there are multiple lengths mentioned describe the maximum). \n",
    "\n",
    "**Hint**: you may want to use re.search or re.findall \n",
    "\n",
    "- For part E, you can use `re.search` and `re.findall`, or anything that works 😳."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:\\\\b\\\\d+\\\\s*(?:year|years)\\\\s*(?:in\\\\s*prison|in\\\\s*custody|probation)?\\\\b)'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['20 years in prison']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a regex pattern to find sentences mentioning year lengths\n",
    "pattern = r'(?:\\b\\d+\\s*(?:year|years)\\s*(?:in\\s*prison|in\\s*custody|probation)?\\b)'\n",
    "\n",
    "matches = re.findall(pattern, pharma_contents)\n",
    "matches\n",
    "\n",
    "# If convicted the CEO may face 20 years in Prison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The CEO, if convicted, may face up to 20 years in prison and might be eligible for five years on probation.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 sentiment analysis  (10 points)\n",
    "\n",
    "A. Subset the press releases to those labeled with one of three topics via `topics_clean`: Civil Rights, Hate Crimes, and Project Safe Childhood. We'll call this `doj_subset` going forward and it should have 717 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in doj_subset: 717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(717, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_of_interest = ['Civil Rights', 'Hate Crimes', 'Project Safe Childhood']\n",
    "\n",
    "doj_subset = doj[doj['topics_clean'].isin(topics_of_interest)]\n",
    "\n",
    "print(\"Number of rows in doj_subset:\", len(doj_subset)) \n",
    "doj_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Write a function that takes one press release string as an input and:\n",
    "\n",
    "- Removes named entities from each press release string (**Hint**: you may want to use `re.sub` with an or condition)\n",
    "- Scores the sentiment of the entire press release using the `SentimentIntensityAnalyzer` and `polarity_scores`\n",
    "- Returns the length-four (negative, positive, neutral, compound) sentiment dictionary (any order is fine)\n",
    "\n",
    "Apply that function to each of the press releases in `doj_subset`. \n",
    "\n",
    "**Hints**: \n",
    "\n",
    "- A function + list comprehension to execute will takes about 30 seconds on a respectable local machine and about 2 mins on jhub; if it's taking a very long time, you may want to check your code for inefficiencies. If you can't fix those, for partial credit on this part/full credit on remainder, you can take a small random sample of the 717\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  \\\n",
      "77     17-1235   \n",
      "155    15-1522   \n",
      "157     16-213   \n",
      "162     16-381   \n",
      "168     14-464   \n",
      "...        ...   \n",
      "13002   09-368   \n",
      "13032   18-775   \n",
      "13034   12-596   \n",
      "13068   18-359   \n",
      "13081  14-1377   \n",
      "\n",
      "                                                             sentiment  \n",
      "77       {'neg': 0.191, 'neu': 0.759, 'pos': 0.05, 'compound': -0.992}  \n",
      "155      {'neg': 0.113, 'neu': 0.82, 'pos': 0.067, 'compound': -0.891}  \n",
      "157     {'neg': 0.088, 'neu': 0.84, 'pos': 0.072, 'compound': -0.7579}  \n",
      "162    {'neg': 0.122, 'neu': 0.796, 'pos': 0.082, 'compound': -0.9037}  \n",
      "168    {'neg': 0.173, 'neu': 0.784, 'pos': 0.043, 'compound': -0.9864}  \n",
      "...                                                                ...  \n",
      "13002  {'neg': 0.145, 'neu': 0.792, 'pos': 0.063, 'compound': -0.9664}  \n",
      "13032   {'neg': 0.078, 'neu': 0.831, 'pos': 0.092, 'compound': 0.5267}  \n",
      "13034  {'neg': 0.153, 'neu': 0.769, 'pos': 0.078, 'compound': -0.9705}  \n",
      "13068  {'neg': 0.134, 'neu': 0.771, 'pos': 0.095, 'compound': -0.9798}  \n",
      "13081  {'neg': 0.145, 'neu': 0.825, 'pos': 0.031, 'compound': -0.9913}  \n",
      "\n",
      "[717 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def process_press_release(press_release):\n",
    "    press_release_clean = re.sub(r'\\b[A-Z][a-z]*\\b', '', press_release)\n",
    "    \n",
    "    sentiment_scores = analyzer.polarity_scores(press_release_clean)\n",
    "    \n",
    "    return sentiment_scores\n",
    "\n",
    "doj_subset['sentiment'] = doj_subset['contents'].apply(process_press_release)\n",
    "print(doj_subset[['id', 'sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  \\\n",
      "77     17-1235   \n",
      "155    15-1522   \n",
      "157     16-213   \n",
      "162     16-381   \n",
      "168     14-464   \n",
      "...        ...   \n",
      "13002   09-368   \n",
      "13032   18-775   \n",
      "13034   12-596   \n",
      "13068   18-359   \n",
      "13081  14-1377   \n",
      "\n",
      "                                                             sentiment  \n",
      "77       {'neg': 0.191, 'neu': 0.759, 'pos': 0.05, 'compound': -0.992}  \n",
      "155      {'neg': 0.113, 'neu': 0.82, 'pos': 0.067, 'compound': -0.891}  \n",
      "157     {'neg': 0.088, 'neu': 0.84, 'pos': 0.072, 'compound': -0.7579}  \n",
      "162    {'neg': 0.122, 'neu': 0.796, 'pos': 0.082, 'compound': -0.9037}  \n",
      "168    {'neg': 0.173, 'neu': 0.784, 'pos': 0.043, 'compound': -0.9864}  \n",
      "...                                                                ...  \n",
      "13002  {'neg': 0.145, 'neu': 0.792, 'pos': 0.063, 'compound': -0.9664}  \n",
      "13032   {'neg': 0.078, 'neu': 0.831, 'pos': 0.092, 'compound': 0.5267}  \n",
      "13034  {'neg': 0.153, 'neu': 0.769, 'pos': 0.078, 'compound': -0.9705}  \n",
      "13068  {'neg': 0.134, 'neu': 0.771, 'pos': 0.095, 'compound': -0.9798}  \n",
      "13081  {'neg': 0.145, 'neu': 0.825, 'pos': 0.031, 'compound': -0.9913}  \n",
      "\n",
      "[717 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "doj_subset['sentiment'] = doj_subset['contents'].apply(process_press_release)\n",
    "print(doj_subset[['id', 'sentiment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Add the four sentiment scores to the `doj_subset` dataframe to create a dataframe: `doj_subset_wscore`. Sort from highest neg to lowest neg score and print the top `id`, `contents`, and `neg` columns of the two most neg press releases. \n",
    "\n",
    "Notes:\n",
    "\n",
    "- Don't worry if your sentiment score differs slightly from our output on GitHub; differences in preprocessing can lead to diff scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>contents</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>14-248</td>\n",
       "      <td>The Department of Justice announced that this morning John W. Ng, 58, of Albuquerque, N.M., made his initial appearance in federal court on a criminal complaint charging him with a hate crime offense.  This charge is related to anti-Semitic threats Ng made against a Jewish woman who owns and operates the Nosh Jewish Delicatessen and Bakery in Albuquerque. Ng was arrested by the FBI on March 7, 2014, based on a criminal complaint alleging that he interfered with the victim’s federally protected rights by threatening her and interfering with her business because of her religion.  According to the criminal complaint, between Jan. 22, 2014, and Feb. 8, 2014, Ng allegedly posted threatening anti-Semitic notes on and in the vicinity of the victim’s business. A criminal complaint merely establishes probable cause, and Ng is presumed innocent unless proven guilty.  If convicted on the offense charged in the criminal complaint, Ng faces a maximum statutory penalty of one year in prison. This matter was investigated by the Albuquerque Division of the FBI and is being prosecuted by Assistant U.S. Attorney Mark T. Baker of the U.S. Attorney’s Office for the District of New Mexico and Trial Attorney AeJean Cha of the U.S. Department of Justice’s Civil Rights Division.</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11593</th>\n",
       "      <td>16-718</td>\n",
       "      <td>In a nine-count indictment unsealed today, two Mississippi correctional officers were charged with beating an inmate and a third was charged with helping to cover it up.  The indictment charged Lawardrick Marsher, 28, and Robert Sturdivant, 47, officers at Mississippi State Penitentiary, in Parchman, Mississippi, with a beating that included kicking, punching and throwing the victim to the ground.  Marsher and Sturdivant were charged with violating the right of K.H., a convicted prisoner, to be free from cruel and unusual punishment.  Sturdivant was also charged with failing to intervene while Marsher was punching and beating K.H.  The indictment alleges that their actions involved the use of a dangerous weapon and resulted in bodily injury to the victim. A third officer, Deonte Pate, 23, was charged along with Marsher and Sturdivant for conspiring to cover up the beating.  The indictment alleges that all three officers submitted false reports and that all three lied to the FBI. If convicted, Marsher and Sturdivant face a maximum sentence of 10 years in prison on the excessive force charges.  Each of the three officers faces up to five years in prison on the conspiracy and false statement charges, and up to 20 years in prison on the false report charges. An indictment is merely an accusation, and the defendants are presumed innocent unless and until proven guilty. This case is being investigated by the FBI’s Jackson Division, with the cooperation of the Mississippi Department of Corrections.  It is being prosecuted by Assistant U.S. Attorney Robert Coleman of the Northern District of Mississippi and Trial Attorney Dana Mulhauser of the Civil Rights Division’s Criminal Section.     Marsher Indictment</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.9964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  \\\n",
       "329    14-248   \n",
       "11593  16-718   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               contents  \\\n",
       "329                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The Department of Justice announced that this morning John W. Ng, 58, of Albuquerque, N.M., made his initial appearance in federal court on a criminal complaint charging him with a hate crime offense.  This charge is related to anti-Semitic threats Ng made against a Jewish woman who owns and operates the Nosh Jewish Delicatessen and Bakery in Albuquerque. Ng was arrested by the FBI on March 7, 2014, based on a criminal complaint alleging that he interfered with the victim’s federally protected rights by threatening her and interfering with her business because of her religion.  According to the criminal complaint, between Jan. 22, 2014, and Feb. 8, 2014, Ng allegedly posted threatening anti-Semitic notes on and in the vicinity of the victim’s business. A criminal complaint merely establishes probable cause, and Ng is presumed innocent unless proven guilty.  If convicted on the offense charged in the criminal complaint, Ng faces a maximum statutory penalty of one year in prison. This matter was investigated by the Albuquerque Division of the FBI and is being prosecuted by Assistant U.S. Attorney Mark T. Baker of the U.S. Attorney’s Office for the District of New Mexico and Trial Attorney AeJean Cha of the U.S. Department of Justice’s Civil Rights Division.   \n",
       "11593  In a nine-count indictment unsealed today, two Mississippi correctional officers were charged with beating an inmate and a third was charged with helping to cover it up.  The indictment charged Lawardrick Marsher, 28, and Robert Sturdivant, 47, officers at Mississippi State Penitentiary, in Parchman, Mississippi, with a beating that included kicking, punching and throwing the victim to the ground.  Marsher and Sturdivant were charged with violating the right of K.H., a convicted prisoner, to be free from cruel and unusual punishment.  Sturdivant was also charged with failing to intervene while Marsher was punching and beating K.H.  The indictment alleges that their actions involved the use of a dangerous weapon and resulted in bodily injury to the victim. A third officer, Deonte Pate, 23, was charged along with Marsher and Sturdivant for conspiring to cover up the beating.  The indictment alleges that all three officers submitted false reports and that all three lied to the FBI. If convicted, Marsher and Sturdivant face a maximum sentence of 10 years in prison on the excessive force charges.  Each of the three officers faces up to five years in prison on the conspiracy and false statement charges, and up to 20 years in prison on the false report charges. An indictment is merely an accusation, and the defendants are presumed innocent unless and until proven guilty. This case is being investigated by the FBI’s Jackson Division, with the cooperation of the Mississippi Department of Corrections.  It is being prosecuted by Assistant U.S. Attorney Robert Coleman of the Northern District of Mississippi and Trial Attorney Dana Mulhauser of the Civil Rights Division’s Criminal Section.     Marsher Indictment   \n",
       "\n",
       "       negative  neutral  positive  compound  \n",
       "329       0.321    0.650     0.029   -0.9957  \n",
       "11593     0.289    0.679     0.032   -0.9964  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part C\n",
    "\n",
    "# parse the sentiment scores into seperate columns and add to doj_subset\n",
    "doj_subset['negative'] = doj_subset['sentiment'].apply(lambda x: x['neg'])\n",
    "doj_subset['neutral'] = doj_subset['sentiment'].apply(lambda x: x['neu'])\n",
    "doj_subset['positive'] = doj_subset['sentiment'].apply(lambda x: x['pos'])\n",
    "doj_subset['compound'] = doj_subset['sentiment'].apply(lambda x: x['compound'])\n",
    "\n",
    "doj_subset_wscore = doj_subset[['id', \n",
    "                                'contents', \n",
    "                                'negative', \n",
    "                                'positive', \n",
    "                                'neutral', \n",
    "                                'compound',\n",
    "                               'topics_clean']].sort_values(by='negative', ascending=False)\n",
    "\n",
    "top_2_neg_press_releases = doj_subset_wscore.head(2)\n",
    "top_2_neg_press_releases[['id', 'contents', 'negative', 'neutral', 'positive', 'compound']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. With the dataframe from part C, find the mean compound sentiment score for each of the three topics in `topics_clean` using group_by and agg.\n",
    "\n",
    "E. Add a 1 sentence interpretation of why we might see the variation in scores (remember that compound is a standardized summary where -1 is most negative; +1 is most positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics_clean\n",
       "Civil Rights             -0.106531\n",
       "Hate Crimes              -0.934456\n",
       "Project Safe Childhood   -0.722572\n",
       "Name: compound, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## agg and find the mean compound score by topic\n",
    "mean_compound_score = doj_subset_wscore.groupby('topics_clean')['compound'].agg('mean')\n",
    "\n",
    "mean_compound_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variation in sentiment scores is due to the variation of each topic -- it is appropriate that hate crimes are very negatively discussed, and civil rights and Project Safe Childhood are discussed less negatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Topic modeling (25 points)\n",
    "\n",
    "For this question, use the `doj_subset_wscores` data that is restricted to civil rights, hate crimes, and project safe childhood and with the sentiment scores added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocess the data by removing stopwords, punctuation, and non-alpha words (5 points)\n",
    "\n",
    "A. Write a function that:\n",
    "\n",
    "- Takes in a single raw string in the `contents` column from that dataframe\n",
    "- Does the following preprocessing steps:\n",
    "\n",
    "    - Converts the words to lowercase\n",
    "    - Removes stopwords, adding the custom stopwords in your code cell below to the default stopwords list\n",
    "    - Only retains alpha words (so removes digits and punctuation)\n",
    "    - Only retains words 4 characters or longer\n",
    "    - Uses the snowball stemmer from nltk to stem\n",
    "\n",
    "- Returns a joined preprocessed string\n",
    "    \n",
    "B. Use `apply` or list comprehension to execute that function and create a new column in the data called `processed_text`\n",
    "    \n",
    "C. Print the `id`, `contents`, and `processed_text` columns for the following press releases:\n",
    "\n",
    "id = 16-718 (this case: https://www.seattletimes.com/nation-world/doj-miami-police-reach-settlement-in-civil-rights-case/)\n",
    "\n",
    "id = 16-217 (this case: https://www.wlbt.com/story/32275512/three-mississippi-correctional-officers-indicted-for-inmate-assault-and-cover-up/)\n",
    "    \n",
    "**Resources**:\n",
    "\n",
    "- Here's code examples for the snowball stemmer: https://www.geeksforgeeks.org/snowball-stemmer-nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = [\"civil\", \"rights\", \"division\", \"department\", \"justice\",\n",
    "                        \"office\", \"attorney\", \"district\", \"case\", \"investigation\", \"assistant\",\n",
    "                       \"trial\", \"assistance\", \"assist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, custom_stopwords):\n",
    "    text = text.lower()\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(custom_stopwords)\n",
    "\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    processed_words = [\n",
    "        stemmer.stem(word) for word in words\n",
    "        if word.isalpha() and\n",
    "        word not in stop_words\n",
    "        and len(word) >= 4\n",
    "    ]\n",
    "\n",
    "    return ' '.join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m doj_subset_wscore[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m doj_subset_wscore[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: preprocess_text(x, custom_stopwords))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4759\u001b[0m         func,\n\u001b[1;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1291\u001b[0m )\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m doj_subset_wscore[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m doj_subset_wscore[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: preprocess_text(x, custom_stopwords))\n",
      "Cell \u001b[0;32mIn[105], line 2\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(text, custom_stopwords)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_text\u001b[39m(text, custom_stopwords):\n\u001b[0;32m----> 2\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m      4\u001b[0m     words \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[1;32m      6\u001b[0m     stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "doj_subset_wscore['processed_text'] = doj_subset_wscore['contents'].apply(lambda x: preprocess_text(x, custom_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code showing the examples\n",
    "miami_case = doj_subset_wscore[doj_subset_wscore['id'] == '16-718']\n",
    "miami_case[['id', 'contents', 'processed_text']]\n",
    "\n",
    "missisippi_case = doj_subset_wscore[doj_subset_wscore['id'] == '16-217']\n",
    "missisippi_case[['id', 'contents', 'processed_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create a document-term matrix from the preprocessed press releases and to explore top words (5 points)\n",
    "\n",
    "A. Use the `create_dtm` function I provide (alternately, feel free to write your own!) and create a document-term matrix using the preprocessed press releases; make sure metadata contains the following columns: `id`, `compound` sentiment column you added, and the `topics_clean` column\n",
    "\n",
    "B. Print the top 10 words for press releases with compound sentiment in the top 5% (so the most positive sentiment)\n",
    "\n",
    "C. Print the top 10 words for press releases with compound sentiment in the bottom 5% (so the most negative sentiment)\n",
    "\n",
    "**Hint**: for these, remember the pandas quantile function from pset one.  \n",
    "\n",
    "D. Print the top 10 words for press releases in each of the three `topics_clean`\n",
    "\n",
    "For steps B - D, to receive full credit, write a function `get_topwords` that helps you avoid duplicated code when you find top words for the different subsets of the data. There are different ways to structure it but one way is to feed it subsetted data (so data subsetted to one topic etc.) and for it to get the top words for that subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dtm(list_of_strings, metadata):\n",
    "    vectorizer = CountVectorizer(lowercase = True)\n",
    "    dtm_sparse = vectorizer.fit_transform(list_of_strings)\n",
    "    dtm_dense_named = pd.DataFrame(dtm_sparse.todense(), \n",
    "        columns=vectorizer.get_feature_names_out())\n",
    "    dtm_dense_named_withid = pd.concat([metadata.reset_index(), dtm_dense_named], axis = 1)\n",
    "    return(dtm_dense_named_withid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('agreement', 176),\n",
       " ('state', 123),\n",
       " ('enforc', 116),\n",
       " ('ensur', 105),\n",
       " ('disabl', 102),\n",
       " ('polic', 88),\n",
       " ('settlement', 88),\n",
       " ('student', 86),\n",
       " ('general', 83),\n",
       " ('communiti', 82)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('assault', 202),\n",
       " ('victim', 185),\n",
       " ('crime', 168),\n",
       " ('offic', 164),\n",
       " ('hate', 135),\n",
       " ('defend', 130),\n",
       " ('sentenc', 111),\n",
       " ('feder', 101),\n",
       " ('charg', 101),\n",
       " ('prosecut', 97)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic 'Hate Crimes':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('victim', 590),\n",
       " ('crime', 533),\n",
       " ('prosecut', 476),\n",
       " ('hate', 472),\n",
       " ('defend', 459),\n",
       " ('sentenc', 455),\n",
       " ('charg', 452),\n",
       " ('guilti', 430),\n",
       " ('feder', 426),\n",
       " ('said', 424)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic 'Civil Rights':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('offic', 627),\n",
       " ('hous', 620),\n",
       " ('discrimin', 541),\n",
       " ('enforc', 531),\n",
       " ('disabl', 509),\n",
       " ('said', 497),\n",
       " ('feder', 475),\n",
       " ('violat', 470),\n",
       " ('state', 443),\n",
       " ('general', 408)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic 'Project Safe Childhood':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('child', 1018),\n",
       " ('exploit', 698),\n",
       " ('sexual', 570),\n",
       " ('safe', 476),\n",
       " ('project', 472),\n",
       " ('childhood', 472),\n",
       " ('pornographi', 447),\n",
       " ('children', 416),\n",
       " ('crimin', 404),\n",
       " ('prosecut', 374)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic 'nan':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = create_dtm(doj_subset_wscore['processed_text'], metadata = doj_subset_wscore[['id', 'compound', 'topics_clean']])\n",
    "\n",
    "def get_topwords(dtm, column_name = 'processed_text', n_top = 10):\n",
    "    text_concat = ' '.join(dtm[column_name])\n",
    "    words = text_concat.split()\n",
    "    word_counts = Counter(words)\n",
    "    top_words = word_counts.most_common(n_top)\n",
    "    return top_words\n",
    "\n",
    "# Part B\n",
    "top_5_percent_threshold = doj_subset_wscore['compound'].quantile(0.95)\n",
    "top_5_percent_dtm = doj_subset_wscore[doj_subset_wscore['compound'] >= top_5_percent_threshold]\n",
    "top_5_percent_positive_words = get_topwords(top_5_percent_dtm)\n",
    "top_5_percent_positive_words\n",
    "\n",
    "# Part C\n",
    "bottom_5_percent_threshold = doj_subset_wscore['compound'].quantile(0.05)\n",
    "bottom_5_percent_dtm = doj_subset_wscore[doj_subset_wscore['compound'] <= bottom_5_percent_threshold]\n",
    "bottom_5_percent_positive_words = get_topwords(bottom_5_percent_dtm)\n",
    "bottom_5_percent_positive_words\n",
    "\n",
    "# Part D\n",
    "unique_topics = doj_subset_wscore['topics_clean'].unique()\n",
    "for topic in unique_topics:\n",
    "    topic_dtm = doj_subset_wscore[doj_subset_wscore['topics_clean'] == topic]\n",
    "    top_words = get_topwords(topic_dtm)\n",
    "    print(f\"Top 10 words for topic '{topic}':\")\n",
    "    top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m top_5_percentile \u001b[38;5;241m=\u001b[39m dtm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.95\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Filter the DTM for rows where 'compound' is greater than or equal to the top 5% quantile\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m top_words_positive \u001b[38;5;241m=\u001b[39m get_top_words(dtm[dtm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m top_5_percentile])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate the bottom 5% quantile for compound sentiment score\u001b[39;00m\n\u001b[1;32m     20\u001b[0m bottom_5_percentile \u001b[38;5;241m=\u001b[39m dtm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.05\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3880\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3878\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) DataFrame?\u001b[39;00m\n\u001b[1;32m   3879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, DataFrame):\n\u001b[0;32m-> 3880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere(key)\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:10615\u001b[0m, in \u001b[0;36mNDFrame.where\u001b[0;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[1;32m  10609\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  10610\u001b[0m                 _chained_assignment_method_msg,\n\u001b[1;32m  10611\u001b[0m                 ChainedAssignmentError,\n\u001b[1;32m  10612\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m  10613\u001b[0m             )\n\u001b[1;32m  10614\u001b[0m other \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mapply_if_callable(other, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m> 10615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_where(cond, other, inplace, axis, level)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:10333\u001b[0m, in \u001b[0;36mNDFrame._where\u001b[0;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[1;32m  10330\u001b[0m     cond \u001b[38;5;241m=\u001b[39m cond\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m  10332\u001b[0m cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mcond \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m cond\n\u001b[0;32m> 10333\u001b[0m cond \u001b[38;5;241m=\u001b[39m cond\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis_number, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m  10335\u001b[0m \u001b[38;5;66;03m# try to align with other\u001b[39;00m\n\u001b[1;32m  10336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, NDFrame):\n\u001b[1;32m  10337\u001b[0m     \u001b[38;5;66;03m# align with me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:5141\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m   5123\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[1;32m   5124\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5139\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5140\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 5141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[1;32m   5142\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5143\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5144\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5145\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5146\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   5147\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   5148\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5149\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   5150\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m   5151\u001b[0m         tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[1;32m   5152\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5521\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5520\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_axes(\n\u001b[1;32m   5522\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[1;32m   5523\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5544\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5541\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   5543\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5544\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[1;32m   5545\u001b[0m     labels, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance, method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[1;32m   5546\u001b[0m )\n\u001b[1;32m   5548\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m   5549\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   5550\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5551\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   5552\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   5553\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   5554\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:4434\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m   4433\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[0;32m-> 4434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4436\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "def create_dtm(texts, metadata):\n",
    "    vectorizer = CountVectorizer(lowercase=True)\n",
    "    dtm_sparse = vectorizer.fit_transform(texts)\n",
    "    dtm_dense = pd.DataFrame(dtm_sparse.todense(), columns=vectorizer.get_feature_names_out())\n",
    "    # Concatenate using a proper index reset for both metadata and dtm_dense to avoid any indexing issues\n",
    "    dtm_final = pd.concat([metadata.reset_index(drop=True), dtm_dense.reset_index(drop=True)], axis=1)\n",
    "    return dtm_final\n",
    "\n",
    "# Main script setup\n",
    "metadata = doj_subset_wscore[['id', 'compound', 'topics_clean']]\n",
    "text = doj_subset_wscore['processed_text']\n",
    "dtm = create_dtm(text, metadata)\n",
    "\n",
    "# Calculate the top 5% quantile for compound sentiment score\n",
    "top_5_percentile = dtm['compound'].quantile(0.95)\n",
    "# Filter the DTM for rows where 'compound' is greater than or equal to the top 5% quantile\n",
    "top_words_positive = get_top_words(dtm[dtm['compound'] >= top_5_percentile])\n",
    "\n",
    "# Calculate the bottom 5% quantile for compound sentiment score\n",
    "bottom_5_percentile = dtm['compound'].quantile(0.05)\n",
    "# Filter the DTM for rows where 'compound' is less than or equal to the bottom 5% quantile\n",
    "top_words_negative = get_top_words(dtm[dtm['compound'] <= bottom_5_percentile])\n",
    "\n",
    "# Display results\n",
    "print(\"Top 10 words in the most positive press releases:\\n\", top_words_positive)\n",
    "print(\"Top 10 words in the most negative press releases:\\n\", top_words_negative)\n",
    "\n",
    "# Analyze top words by topic\n",
    "topics = dtm['topics_clean'].unique()\n",
    "topic_words = {}\n",
    "for topic in topics:\n",
    "    topic_dtm = dtm[dtm['topics_clean'] == topic]\n",
    "    topic_words[topic] = get_top_words(topic_dtm)\n",
    "    print(f\"\\nTop 10 words for '{topic}':\\n\", topic_words[topic])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Estimate a topic model using those preprocessed words (5 points)\n",
    "\n",
    "A. Going back to the preprocessed words from part 2.3.1, estimate a topic model with 3 topics, since you want to see if the unsupervised topic models recover different themes for each of the three manually-labeled areas (civil rights; hate crimes; project safe childhood). You have free rein over the other topic model parameters beyond the number of topics.\n",
    "\n",
    "B. After estimating the topic model, print the top 15 words in each topic.\n",
    "\n",
    "**Hints and Resources**:\n",
    "\n",
    "- Same topic modeling resources linked to above\n",
    "- Make sure to use the `random_state` argument within the model so that the numbering of topics does not move around between runs of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering reduced the dictionary size from 6756 to 1151.\n"
     ]
    }
   ],
   "source": [
    "selected_topics = ['Civil Rights', 'Hate Crimes', 'Project Safe Childhood']\n",
    "\n",
    "filtered_df = doj_subset_wscore[doj_subset_wscore['topics_clean'].isin(selected_topics)]\n",
    "\n",
    "tokenized_texts = [wordpunct_tokenize(text) for text in filtered_df.processed_text]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "initial_dictionary_size = len(dictionary)  # Store initial size for comparison\n",
    "\n",
    "doc_count = filtered_df.shape[0]  # Number of documents\n",
    "lower_threshold = round(doc_count * 0.023)\n",
    "upper_threshold = round(doc_count * 0.977) # thresholds make this 2 SDs from the mean\n",
    "\n",
    "dictionary.filter_extremes(no_below = lower_threshold, no_above = upper_threshold)\n",
    "filtered_dictionary_size = len(dictionary)  # Store size after filtering\n",
    "\n",
    "print(f'Filtering reduced the dictionary size from {initial_dictionary_size} to {filtered_dictionary_size}.')\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus = corpus,\n",
    "    num_topics = 3,\n",
    "    id2word = dictionary,\n",
    "    passes = 10,\n",
    "    alpha = 'auto',\n",
    "    per_word_topics = True,\n",
    "    random_state = 100 # ensures reproducability\n",
    ")\n",
    "\n",
    "topics = lda_model.print_topics(num_words = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 top 15 words: ['victim', 'charg', 'sentenc', 'prosecut', 'defend', 'feder', 'guilti', 'crime', 'said', 'indict', 'hate', 'prison', 'investig', 'year', 'assault']\n",
      "Topic 2 top 15 words: ['child', 'exploit', 'sexual', 'safe', 'project', 'childhood', 'pornographi', 'children', 'crimin', 'prosecut', 'victim', 'sentenc', 'ceo', 'minor', 'abus']\n",
      "Topic 3 top 15 words: ['hous', 'discrimin', 'disabl', 'enforc', 'agreement', 'state', 'said', 'court', 'alleg', 'requir', 'feder', 'settlement', 'violat', 'fair', 'general']\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(topics):\n",
    "    words = [word.split(\"*\")[1].strip(' \"') for word in topic[1].split(\" + \")]\n",
    "    print(f\"Topic {index + 1} top 15 words: {words}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Add topics back to main data and explore correlation between manual labels and our estimated topics (10 points)\n",
    "\n",
    "A. Extract the document-level topic probabilities. Within `get_document_topics`, use the argument `minimum_probability` = 0 to make sure all 3 topic probabilities are returned. Write an assert statement to make sure the length of the list is equal to the number of rows in the `doj_subset_wscores` dataframe\n",
    "\n",
    "B. Add the topic probabilities to the `doj_subset_wscores` dataframe as columns and create a column, `top_topic`, that reflects each document to its highest-probability topic (eg topic 1, 2, or 3)\n",
    "\n",
    "C. For each of the manual labels in `topics_clean` (Hate Crime, Civil Rights, Project Safe Childhood), print the breakdown of the % of documents with each top topic (so, for instance, Hate Crime has 246 documents-- if 123 of those documents are coded to topic_1, that would be 50%; and so on). **Hint**: pd.crosstab and normalize may be helpful: https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.crosstab.html\n",
    "\n",
    "D. Using a couple press releases as examples, write a 1-2 sentence interpretation of why some of the manual topics map on more cleanly to an estimated topic than other manual topic(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.99864405), (1, 0.00060329743), (2, 0.0007526972)],\n",
       " [(0, 0.9991564), (1, 0.00037534026), (2, 0.00046828896)],\n",
       " [(0, 0.9992957), (1, 0.0003133395), (2, 0.00039093444)],\n",
       " [(0, 0.9993539), (1, 0.00028743627), (2, 0.00035861655)],\n",
       " [(0, 0.9988445), (1, 0.00051409745), (2, 0.0006414078)]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_probabilities = [lda_model.get_document_topics(item, minimum_probability = 0) \n",
    "                       for item in corpus\n",
    "]\n",
    "\n",
    "assert len(topic_probabilities) == doj_subset_wscore.shape[0]\n",
    "topic_probabilities[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here to add those topic probabilities to the dataframe\n",
    "### Intialize columns\n",
    "#for i in range(3):\n",
    "    #doj_subset_wscore[f'topic_{i + 1}_prob'] = 0\n",
    "\n",
    "## Iterate over each document's topic probabilities\n",
    "#for index, probabilities in enumerate(topic_probabilities):\n",
    "    #for topic_id, prob in probabilities:\n",
    "        #doj_subset_wscore.at[index, f'topic_{topic_id + 1}_prob'] = prob\n",
    "\n",
    "    #max_topic = max(probabilities, key=lambda x: x[1])\n",
    "\n",
    "    #doj_subset_wscore.at[index, 'top_topic'] = max_topic[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    doj_subset_wscore[f'topic_{i}_prob'] = 0\n",
    "\n",
    "# Iterate over each document's topic probabilities\n",
    "for index, probabilities in enumerate(topic_probabilities):\n",
    "    for topic_id, prob in probabilities:\n",
    "        doj_subset_wscore.at[index, f'topic_{topic_id}_prob'] = prob\n",
    "\n",
    "    max_topic = max(probabilities, key=lambda x: x[1])\n",
    "    \n",
    "    doj_subset_wscore.at[index, 'top_topic'] = max_topic[0] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>top_topic</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topics_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Civil Rights</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hate Crimes</th>\n",
       "      <td>22.727273</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Safe Childhood</th>\n",
       "      <td>63.636364</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>18.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "top_topic                     1.0        2.0        3.0\n",
       "topics_clean                                           \n",
       "Civil Rights            33.333333  66.666667   0.000000\n",
       "Hate Crimes             22.727273  50.000000  27.272727\n",
       "Project Safe Childhood  63.636364  18.181818  18.181818"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##C. For each of the manual labels in `topics_clean` \n",
    "#(Hate Crime, Civil Rights, Project Safe Childhood), print the breakdown of the \n",
    "#% of documents with each top topic (so, for instance, Hate Crime has 246 documents-- \n",
    "#if 123 of those documents are coded to topic_1, that would be 50%; and so on). \n",
    "#**Hint**: pd.crosstab and normalize may be helpful: https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.crosstab.html\n",
    "\n",
    "topic_dist = pd.crosstab(doj_subset_wscore['topics_clean'], doj_subset_wscore['top_topic'], normalize='index')\n",
    "\n",
    "topic_dist_percent = topic_dist * 100\n",
    "\n",
    "topic_dist_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extend the analysis from unigrams to bigrams (10 points)\n",
    "\n",
    "In the previous question, you found top words via a unigram representation of the text. Now, we want to see how those top words change with bigrams (pairs of words)\n",
    "\n",
    "A. Using the `doj_subset_wscore` data and the `processed_text` column (so the words after stemming/other preprocessing), create a column in the data called `processed_text_bigrams` that combines each consecutive pairs of word into a bigram separated by an underscore. Eg:\n",
    "\n",
    "\"depart reach settlem\" would become \"depart_reach reach_settlem\"\n",
    "\n",
    "Do this by writing a function `create_bigram_onedoc` that takes in a single `processed_text` string and returns a string with its bigrams structured similarly to above example\n",
    " \n",
    "**Hint**: there are many ways to solve but `zip` may be helpful: https://stackoverflow.com/questions/21303224/iterate-over-all-pairs-of-consecutive-items-in-a-list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>processed_text_bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>16-217</td>\n",
       "      <td>reach comprehens settlement agreement citi miami miami polic resolv shoot offic announc princip deputi general vanita gupta head wifredo ferrer southern florida settlement approv miami citi commiss today effect agreement sign parti resolv claim stem shoot offic conduct violent crime control enforc find issu juli identifi pattern practic excess forc shoot violat fourth amend constitut citi complianc settlement monitor independ review former tampa florida polic chief jane castor settlement agreement citi implement comprehens reform ensur constitut polic support public trust settlement agreement design minim shoot effect quick investig shoot occur measur includ settlement repres renew commit citi miami chief rodolfo llane provid constitut polic miami resid protect public safeti sustain reform said princip deputi general gupta agreement help strengthen relationship communiti serv improv account offic fire weapon unlaw provid communiti particip enforc today agreement result joint effort citi miami ensur miami polic continu effort make communiti safe protect sacr constitut citizen said ferrer oversight communic agreement seek make perman posit chang former chief orosa chief llane made applaud citi commiss settlement agreement build upon import reform implement citi sinc issu find includ conduct attorney staff special litig section southern florida</td>\n",
       "      <td>reach_comprehens comprehens_settlement settlement_agreement agreement_citi citi_miami miami_miami miami_polic polic_resolv resolv_shoot shoot_offic offic_announc announc_princip princip_deputi deputi_general general_vanita vanita_gupta gupta_head head_wifredo wifredo_ferrer ferrer_southern southern_florida florida_settlement settlement_approv approv_miami miami_citi citi_commiss commiss_today today_effect effect_agreement agreement_sign sign_parti parti_resolv resolv_claim claim_stem stem_shoot shoot_offic offic_conduct conduct_violent violent_crime crime_control control_enforc enforc_find find_issu issu_juli juli_identifi identifi_pattern pattern_practic practic_excess excess_forc forc_shoot shoot_violat violat_fourth fourth_amend amend_constitut constitut_citi citi_complianc complianc_settlement settlement_monitor monitor_independ independ_review review_former former_tampa tampa_florida florida_polic polic_chief chief_jane jane_castor castor_settlement settlement_agreement agreement_citi citi_implement implement_comprehens comprehens_reform reform_ensur ensur_constitut constitut_polic polic_support support_public public_trust trust_settlement settlement_agreement agreement_design design_minim minim_shoot shoot_effect effect_quick quick_investig investig_shoot shoot_occur occur_measur measur_includ includ_settlement settlement_repres repres_renew renew_commit commit_citi citi_miami miami_chief chief_rodolfo rodolfo_llane llane_provid provid_constitut constitut_polic polic_miami miami_resid resid_protect protect_public public_safeti safeti_sustain sustain_reform reform_said said_princip princip_deputi deputi_general general_gupta gupta_agreement agreement_help help_strengthen strengthen_relationship relationship_communiti communiti_serv serv_improv improv_account account_offic offic_fire fire_weapon weapon_unlaw unlaw_provid provid_communiti communiti_particip particip_enforc enforc_today today_agreement agreement_result result_joint joint_effort effort_citi citi_miami miami_ensur ensur_miami miami_polic polic_continu continu_effort effort_make make_communiti communiti_safe safe_protect protect_sacr sacr_constitut constitut_citizen citizen_said said_ferrer ferrer_oversight oversight_communic communic_agreement agreement_seek seek_make make_perman perman_posit posit_chang chang_former former_chief chief_orosa orosa_chief chief_llane llane_made made_applaud applaud_citi citi_commiss commiss_settlement settlement_agreement agreement_build build_upon upon_import import_reform reform_implement implement_citi citi_sinc sinc_issu issu_find find_includ includ_conduct conduct_attorney attorney_staff staff_special special_litig litig_section section_southern southern_florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "6727  16-217   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           processed_text  \\\n",
       "6727  reach comprehens settlement agreement citi miami miami polic resolv shoot offic announc princip deputi general vanita gupta head wifredo ferrer southern florida settlement approv miami citi commiss today effect agreement sign parti resolv claim stem shoot offic conduct violent crime control enforc find issu juli identifi pattern practic excess forc shoot violat fourth amend constitut citi complianc settlement monitor independ review former tampa florida polic chief jane castor settlement agreement citi implement comprehens reform ensur constitut polic support public trust settlement agreement design minim shoot effect quick investig shoot occur measur includ settlement repres renew commit citi miami chief rodolfo llane provid constitut polic miami resid protect public safeti sustain reform said princip deputi general gupta agreement help strengthen relationship communiti serv improv account offic fire weapon unlaw provid communiti particip enforc today agreement result joint effort citi miami ensur miami polic continu effort make communiti safe protect sacr constitut citizen said ferrer oversight communic agreement seek make perman posit chang former chief orosa chief llane made applaud citi commiss settlement agreement build upon import reform implement citi sinc issu find includ conduct attorney staff special litig section southern florida   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         processed_text_bigrams  \n",
       "6727  reach_comprehens comprehens_settlement settlement_agreement agreement_citi citi_miami miami_miami miami_polic polic_resolv resolv_shoot shoot_offic offic_announc announc_princip princip_deputi deputi_general general_vanita vanita_gupta gupta_head head_wifredo wifredo_ferrer ferrer_southern southern_florida florida_settlement settlement_approv approv_miami miami_citi citi_commiss commiss_today today_effect effect_agreement agreement_sign sign_parti parti_resolv resolv_claim claim_stem stem_shoot shoot_offic offic_conduct conduct_violent violent_crime crime_control control_enforc enforc_find find_issu issu_juli juli_identifi identifi_pattern pattern_practic practic_excess excess_forc forc_shoot shoot_violat violat_fourth fourth_amend amend_constitut constitut_citi citi_complianc complianc_settlement settlement_monitor monitor_independ independ_review review_former former_tampa tampa_florida florida_polic polic_chief chief_jane jane_castor castor_settlement settlement_agreement agreement_citi citi_implement implement_comprehens comprehens_reform reform_ensur ensur_constitut constitut_polic polic_support support_public public_trust trust_settlement settlement_agreement agreement_design design_minim minim_shoot shoot_effect effect_quick quick_investig investig_shoot shoot_occur occur_measur measur_includ includ_settlement settlement_repres repres_renew renew_commit commit_citi citi_miami miami_chief chief_rodolfo rodolfo_llane llane_provid provid_constitut constitut_polic polic_miami miami_resid resid_protect protect_public public_safeti safeti_sustain sustain_reform reform_said said_princip princip_deputi deputi_general general_gupta gupta_agreement agreement_help help_strengthen strengthen_relationship relationship_communiti communiti_serv serv_improv improv_account account_offic offic_fire fire_weapon weapon_unlaw unlaw_provid provid_communiti communiti_particip particip_enforc enforc_today today_agreement agreement_result result_joint joint_effort effort_citi citi_miami miami_ensur ensur_miami miami_polic polic_continu continu_effort effort_make make_communiti communiti_safe safe_protect protect_sacr sacr_constitut constitut_citizen citizen_said said_ferrer ferrer_oversight oversight_communic communic_agreement agreement_seek seek_make make_perman perman_posit posit_chang chang_former former_chief chief_orosa orosa_chief chief_llane llane_made made_applaud applaud_citi citi_commiss commiss_settlement settlement_agreement agreement_build build_upon upon_import import_reform reform_implement implement_citi citi_sinc sinc_issu issu_find find_includ includ_conduct conduct_attorney attorney_staff staff_special special_litig litig_section section_southern southern_florida  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_bigram_onedoc(processed_text):\n",
    "    if not isinstance(processed_text, str):\n",
    "        return \"\"  \n",
    "\n",
    "    words = processed_text.split()\n",
    "    bigrams = [\"_\".join(pair) for pair in zip(words, words[1:])]\n",
    "    return \" \".join(bigrams)\n",
    "\n",
    "doj_subset_wscore['processed_text_bigrams'] = doj_subset_wscore['processed_text'].apply(create_bigram_onedoc)\n",
    "\n",
    "doj_subset_wscore[doj_subset_wscore['id'] == '16-217'][['id', 'processed_text', 'processed_text_bigrams']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Use the create_dtm function and the `processed_text_bigrams` column to create a document-term matrix (`dtm_bigram`) with these bigrams. Keep the following three columns in the data: `id`, `topics_clean`, and `compound` \n",
    "\n",
    "D. Print the (1) dimensions of the `dtm` matrix from question 2.2  and (2) the dimensions of the `dtm_bigram` matrix. Comment on why the bigram matrix has more dimensions than the unigram matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Find and print the 10 most prevelant bigrams for each of the three topics_clean using the `get_topwords` function from 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram DTM dimensions: (717, 6760)\n",
      "Bigram DTM dimensions: (1398, 71336)\n"
     ]
    }
   ],
   "source": [
    "metadata = doj_subset_wscore[['id', 'topics_clean', 'compound']]\n",
    "\n",
    "list_of_strings = doj_subset_wscore['processed_text_bigrams']\n",
    "\n",
    "dtm_bigram = create_dtm(list_of_strings, metadata)\n",
    "\n",
    "print(\"Unigram DTM dimensions:\", dtm.shape)\n",
    "print(\"Bigram DTM dimensions:\", dtm_bigram.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                  int64\n",
      "id                   float64\n",
      "topics_clean         float64\n",
      "compound             float64\n",
      "aaron_ford             int64\n",
      "                      ...   \n",
      "zone_varianc           int64\n",
      "zunggeemog_noel        int64\n",
      "zunggeemog_prompt      int64\n",
      "zunggeemog_write       int64\n",
      "zwengel_princeton      int64\n",
      "Length: 71336, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtm_bigram = dtm_bigram.apply(pd.to_numeric, errors='coerce')\n",
    "print(dtm_bigram.dtypes)\n",
    "\n",
    "dtm_bigram = dtm_bigram.fillna(0)\n",
    "\n",
    "def get_topwords(dtm, n_topwords):\n",
    "    top_words = {}\n",
    "    for col in dtm.columns:\n",
    "        top = dtm[col].nlargest(n_topwords).index.tolist()\n",
    "        top_words[col] = top\n",
    "    return top_words\n",
    "\n",
    "# top words\n",
    "top_bigrams_per_topic = get_topwords(dtm_bigram, 10)\n",
    "\n",
    "#top bigrams\n",
    "for topic, bigrams in top_bigrams_per_topic.items():\n",
    "    print(f\"Top 10 bigrams for {topic}: {bigrams}\")\n",
    "\n",
    "print(dtm_bigram.head())\n",
    "print(dtm_bigram.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': [275, 321, 239, 571, 272, 152, 259, 33, 49, 609],\n",
       " 'id': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'topics_clean': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'compound': [694, 649, 663, 671, 698, 690, 650, 601, 644, 700],\n",
       " 'aaron_ford': [307, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'aaron_latham': [39, 66, 287, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'aaron_mcgrath': [388, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'aaron_parrish': [361, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'aaron_polster': [211, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'aaron_rice': [206, 53, 63, 106, 29, 34, 69, 130, 213, 240],\n",
       " 'abandon_children': [421, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abbat_washington': [586, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abbi_broughton': [83, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abbott_act': [278, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abbott_indict': [86, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abdomen_area': [535, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abdomen_larg': [103, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abdomen_previous': [275, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abduct_alert': [517, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abduct_case': [594, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abduct_interrog': [396, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abduct_moor': [396, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abduct_respons': [601, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abdul_kallon': [294, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abdul_karim': [558, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abel_mark': [82, 323, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abendroth_western': [299, 535, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abet_anoth': [353, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abet_friend': [55, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abet_hate': [16, 111, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abet_kidnap': [16, 111, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abet_premedit': [116, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abhorr_act': [228, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abhorr_conduct': [264, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abhorr_consid': [154, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abhorr_crime': [401, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abhorr_crimin': [24, 28, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abhorr_venom': [92, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abhorr_work': [236, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abid_duti': [561, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abid_fair': [662, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abid_rluipa': [658, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_adapt': [601, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_american': [670, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_build': [469, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_citizen': [605, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_combat': [230, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_constitut': [457, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_court': [605, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_dine': [628, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_disciplin': [204, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_effect': [372, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_establish': [486, 580, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abil_exercis': [502, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_express': [57, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_hous': [627, 486, 637, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abil_inabl': [622, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_live': [255, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_peopl': [395, 675, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abil_perform': [596, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_practic': [178, 457, 595, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abil_proper': [372, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_protect': [601, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_respons': [52, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_violat': [457, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abil_whether': [606, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_access': [616, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_build': [595, 617, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abl_cast': [545, 685, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abl_contribut': [680, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_creat': [407, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_decid': [570, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_enforc': [230, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_enjoy': [460, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_execut': [8, 0, 1, 2, 3, 4, 5, 6, 7, 9],\n",
       " 'abl_expect': [172, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_find': [140, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_help': [114, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_inflict': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_interact': [646, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_live': [70, 235, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abl_need': [628, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_occupi': [38, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_prey': [357, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_pull': [124, 355, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abl_purchas': [565, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_reach': [350, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_rescu': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_secur': [549, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_serv': [676, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_show': [685, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_singl': [105, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_stay': [572, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abl_trace': [487, 498, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abl_trust': [615, 641, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abl_work': [672, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ablaz_sworn': [440, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abolit_practic': [672, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abomin_civil': [254, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abort_servic': [419, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abramov_accomplic': [123, 156, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abramov_arrest': [156, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abramov_continu': [123, 156, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abramov_convict': [156, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abramov_dual': [123, 156, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abramov_five': [123, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abramov_threaten': [123, 156, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abramov_travel': [123, 156, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abras_right': [103, 115, 210, 275, 0, 1, 2, 3, 4, 5],\n",
       " 'abridg_sacr': [198, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abroad_citizen': [365, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abroad_either': [370, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abroad_pursu': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abroad_said': [401, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absenc_agreement': [703, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absenc_danger': [157, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absenc_empathi': [455, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absenc_statutori': [688, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absent_show': [654, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absente_vote': [385, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absolut_argument': [201, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absolut_critic': [169, 246, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'absolut_essenti': [682, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'absolut_reprehens': [69, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_accord': [475, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_act': [285, 348, 430, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abus_action': [93, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_addit': [310, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_adopt': [332, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_attempt': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_attorney': [326, 333, 345, 364, 368, 370, 381, 382, 397, 431],\n",
       " 'abus_author': [291, 246, 267, 335, 40, 44, 52, 73, 93, 99],\n",
       " 'abus_badg': [251, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_beeman': [449, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_behavior': [426, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_boy': [195, 234, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_campbel': [338, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_caus': [138, 179, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_charg': [215, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_child': [265, 127, 423, 220, 350, 433, 0, 1, 2, 3],\n",
       " 'abus_children': [285, 344, 493, 233, 258, 350, 424, 439, 442, 461],\n",
       " 'abus_conduct': [87, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_continu': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_control': [363, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_correct': [428, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_count': [195, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_counti': [276, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_defend': [332, 368, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_dishonor': [294, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_distribut': [357, 433, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_enforc': [192, 298, 333, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abus_ensur': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_evid': [123, 156, 461, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abus_exploit': [601, 344, 370, 464, 0, 1, 2, 3, 4, 5],\n",
       " 'abus_extens': [108, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_femal': [455, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_final': [421, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_flagrant': [99, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_furthermor': [310, 338, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_girl': [127, 461, 489, 220, 475, 0, 1, 2, 3, 4],\n",
       " 'abus_hand': [428, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_hard': [277, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_hostil': [216, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_iberia': [99, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_imag': [421, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_includ': [537, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_individu': [251, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_inflict': [167, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_inmat': [93, 99, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_innoc': [344, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_internet': [127, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_iphon': [127, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_jansen': [309, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_jayavarman': [518, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_launch': [120, 123, 127, 156, 163, 167, 173, 185, 195, 214],\n",
       " 'abus_least': [258, 285, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_live': [621, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_lose': [114, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_member': [231, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_minor': [421, 123, 156, 333, 350, 368, 439, 449, 0, 1],\n",
       " 'abus_multipl': [309, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_offic': [490, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_other': [127, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_peopl': [402, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_pervert': [108, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_place': [264, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_portray': [417, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_posit': [154, 276, 401, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abus_power': [76, 52, 62, 87, 194, 251, 294, 334, 335, 391],\n",
       " 'abus_pretrial': [99, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_produc': [601, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_prosecut': [167, 344, 424, 442, 0, 1, 2, 3, 4, 5],\n",
       " 'abus_public': [246, 557, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_record': [220, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_sacr': [527, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_said': [285, 418, 601, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abus_second': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_sent': [479, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_sexual': [195, 234, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_sometim': [231, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_steadfast': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_stream': [127, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_subjug': [363, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_success': [344, 424, 442, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abus_suffer': [361, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_sworn': [402, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_three': [365, 123, 156, 368, 0, 1, 2, 3, 4, 5],\n",
       " 'abus_toddler': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_transport': [538, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_trust': [260, 299, 535, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'abus_use': [231, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_victim': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_violenc': [343, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_violent': [344, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_vulner': [357, 401, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'abus_well': [368, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_year': [363, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'abus_young': [233, 298, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'academ_enforc': [372, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academ_excel': [694, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academ_extracurricular': [646, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academ_interven': [657, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academ_program': [704, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academ_progress': [705, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academ_success': [702, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_build': [467, 407, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'academi_custodi': [476, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_exercis': [467, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_indict': [453, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_public': [514, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_request': [407, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_subject': [514, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_train': [291, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'academi_use': [453, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_bealoni': [380, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_bracken': [320, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_door': [405, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_onto': [183, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_stiffey': [243, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_stop': [253, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_surveil': [183, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acceler_transport': [327, 422, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accept_barrett': [137, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_document': [642, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_employ': [452, 603, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accept_fisher': [141, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_give': [134, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_guilti': [327, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_injuri': [294, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_judg': [285, 528, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accept_member': [417, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_montana': [679, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_other': [485, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_plea': [37, 589, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accept_profession': [619, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_respons': [158, 256, 276, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'accept_rule': [416, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_societi': [41, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accept_toler': [662, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_academ': [646, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_access': [686, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_accommod': [619, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_adapt': [618, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_addit': [694, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_adequ': [479, 676, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_afford': [560, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_agreement': [659, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_aisl': [668, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_apart': [109, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_appropri': [318, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_aspect': [698, 700, 706, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_attempt': [659, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_ballot': [545, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_barrier': [664, 651, 656, 679, 0, 1, 2, 3, 4, 5],\n",
       " 'access_basic': [633, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_better': [310, 338, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_board': [418, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_build': [590, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_bulletin': [589, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_child': [388, 345, 464, 615, 640, 654, 686, 0, 1, 2],\n",
       " 'access_citi': [706, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_clinic': [183, 351, 371, 419, 0, 1, 2, 3, 4, 5],\n",
       " 'access_communiti': [536, 659, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_complaint': [637, 686, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_complex': [656, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_complianc': [700, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_consent': [675, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_construct': [618, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_coordin': [700, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_counti': [708, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_countri': [604, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_cours': [657, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_court': [201, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_credit': [560, 582, 644, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_cultur': [686, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_curb': [651, 706, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_curriculum': [705, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_democrat': [693, 699, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_deni': [656, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_design': [616, 681, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_dine': [616, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_disabl': [599, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_document': [529, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_download': [270, 464, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_educ': [704, 646, 694, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_elect': [708, 675, 691, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_elig': [699, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_enter': [659, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_equal': [667, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_facil': [669, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_fair': [630, 664, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_famili': [697, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_featur': [599, 554, 633, 651, 656, 664, 0, 1, 2, 3],\n",
       " 'access_food': [611, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_fulli': [681, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_function': [600, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_govern': [683, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_guidelin': [698, 700, 706, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_health': [318, 457, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_hispan': [602, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_homeland': [600, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_hous': [639, 697, 391, 559, 570, 578, 599, 607, 614, 629],\n",
       " 'access_imag': [388, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_improv': [633, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_individu': [668, 618, 657, 659, 681, 708, 0, 1, 2, 3],\n",
       " 'access_initi': [698, 700, 706, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_intent': [377, 388, 462, 538, 0, 1, 2, 3, 4, 5],\n",
       " 'access_interpret': [683, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_jurisdict': [708, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_languag': [602, 683, 692, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_law': [633, 651, 675, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_lawsuit': [625, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_learn': [675, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_limit': [602, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_maintain': [708, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_march': [675, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_minor': [421, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_modif': [629, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_nationwid': [700, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_necessari': [140, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_network': [388, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_offer': [529, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_opportun': [554, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_otherwis': [657, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_outcom': [457, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_page': [619, 668, 681, 698, 700, 706, 0, 1, 2, 3],\n",
       " 'access_park': [698, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_payment': [599, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_peopl': [679, 599, 618, 706, 0, 1, 2, 3, 4, 5],\n",
       " 'access_person': [698, 700, 656, 664, 599, 600, 618, 651, 679, 0],\n",
       " 'access_plan': [630, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_polici': [630, 683, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_poll': [675, 706, 708, 633, 0, 1, 2, 3, 4, 5],\n",
       " 'access_program': [683, 659, 700, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_protect': [602, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_provis': [629, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_public': [485, 687, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_read': [633, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_realiti': [630, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_receiv': [657, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_reproduct': [107, 183, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_requir': [630, 629, 656, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_restroom': [546, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_retain': [706, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_right': [691, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_rluipa': [563, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_rooftop': [616, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_rout': [618, 599, 616, 651, 656, 664, 681, 0, 1, 2],\n",
       " 'access_seat': [668, 681, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_sent': [457, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_servic': [140, 390, 646, 686, 0, 1, 2, 3, 4, 5],\n",
       " 'access_settlement': [698, 708, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_sexual': [346, 359, 369, 459, 0, 1, 2, 3, 4, 5],\n",
       " 'access_site': [344, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_social': [487, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_standard': [697, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_state': [698, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_suspend': [457, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_technolog': [657, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_term': [701, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_therapeut': [672, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_throughout': [698, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_titl': [633, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_transpar': [686, 710, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_transport': [554, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_treatment': [325, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_unit': [656, 664, 679, 697, 0, 1, 2, 3, 4, 5],\n",
       " 'access_usabl': [616, 618, 668, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'access_video': [377, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_view': [345, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_violat': [656, 664, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_vote': [633, 675, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_voter': [701, 708, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'access_walk': [651, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_websit': [318, 388, 554, 615, 631, 633, 640, 647, 654, 659],\n",
       " 'access_wheelchair': [599, 629, 651, 664, 0, 1, 2, 3, 4, 5],\n",
       " 'access_without': [296, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'access_work': [698, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accid_find': [676, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accid_mistak': [349, 520, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accident_overdos': [363, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_afford': [428, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_amen': [310, 338, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_applic': [497, 678, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_around': [591, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_call': [687, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_certain': [497, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_citi': [610, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_colleg': [703, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_color': [567, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_contact': [567, 591, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_deni': [651, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_deserv': [622, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_disabl': [622, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_employe': [593, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_furnish': [707, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_healthcar': [318, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_includ': [572, 615, 619, 622, 640, 647, 0, 1, 2, 3],\n",
       " 'accommod_individu': [497, 647, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_inform': [647, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_keep': [613, 635, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_move': [619, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_must': [681, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_necessari': [610, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_need': [613, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_oblig': [707, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_oper': [707, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_polici': [628, 497, 551, 621, 627, 0, 1, 2, 3, 4],\n",
       " 'accommod_pose': [572, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_pregnant': [622, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_rental': [651, 664, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_request': [622, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_requir': [497, 619, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_restaur': [567, 591, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_said': [622, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_settlement': [567, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_similar': [613, 635, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_student': [613, 635, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accommod_titl': [619, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_treat': [591, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_without': [283, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_worker': [622, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_workplac': [606, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accommod_would': [606, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_affidavit': [36, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_comprehens': [537, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_languag': [57, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_line': [632, 649, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accompani_member': [448, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_realtor': [341, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_telephon': [545, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_white': [145, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accompani_wingo': [100, 289, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accomplic_abduct': [396, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accomplic_christian': [315, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accomplic_corner': [123, 156, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accomplic_drove': [531, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accomplic_instruct': [531, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accomplic_load': [531, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accomplish_combat': [350, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accomplish_continu': [70, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accomplish_document': [649, 650, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accomplish_fair': [560, 582, 597, 625, 638, 644, 0, 1, 2, 3],\n",
       " 'accomplish_includ': [630, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_admiss': [424, 442, 138, 163, 173, 258, 310, 328, 330, 331],\n",
       " 'accord_affidavit': [339, 342, 7, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'accord_alleg': [50, 59, 125, 314, 451, 532, 0, 1, 2, 3],\n",
       " 'accord_autopsi': [128, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_bill': [484, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_charg': [110, 193, 287, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'accord_compani': [553, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_complaint': [125, 220, 622, 83, 140, 175, 215, 238, 435, 486],\n",
       " 'accord_court': [417, 214, 256, 298, 498, 604, 67, 103, 109, 127],\n",
       " 'accord_crimin': [0, 124, 480, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accord_defend': [221, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_detent': [399, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_document': [452, 98, 103, 109, 115, 152, 154, 164, 210, 218],\n",
       " 'accord_estim': [337, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_evid': [461, 489, 128, 156, 169, 285, 52, 55, 97, 123],\n",
       " 'accord_fact': [360, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_feder': [133, 279, 349, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'accord_fellow': [546, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_file': [49, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_govern': [439, 276, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accord_guilti': [44, 78, 141, 157, 456, 522, 0, 1, 2, 3],\n",
       " 'accord_heath': [402, 557, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accord_incid': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_indict': [30, 363, 17, 43, 59, 120, 139, 191, 208, 474],\n",
       " 'accord_inform': [45, 84, 92, 95, 104, 129, 212, 236, 319, 336],\n",
       " 'accord_juli': [685, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_laboratori': [259, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_law': [251, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_mcgee': [299, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_morgan': [41, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_must': [279, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_offic': [349, 520, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accord_order': [685, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_plea': [9, 12, 14, 31, 39, 66, 72, 106, 117, 172],\n",
       " 'accord_plead': [166, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_poll': [682, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_punn': [296, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_roeder': [347, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_second': [480, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_sentenc': [505, 276, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accord_spread': [619, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_state': [185, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_statement': [401, 521, 569, 587, 0, 1, 2, 3, 4, 5],\n",
       " 'accord_supersed': [434, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accord_testimoni': [226, 211, 55, 57, 97, 135, 170, 332, 400, 0],\n",
       " 'accord_today': [308, 410, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accost_victim': [103, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_account': [133, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_action': [74, 119, 246, 315, 340, 361, 441, 0, 1, 2],\n",
       " 'account_adult': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_affirm': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_arson': [306, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_attempt': [586, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_betray': [52, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_build': [655, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_capac': [504, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_charg': [139, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_color': [139, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_commit': [53, 63, 97, 130, 376, 0, 1, 2, 3, 4],\n",
       " 'account_communiti': [643, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_conduct': [400, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_continu': [92, 445, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'account_contrast': [372, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_cours': [649, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_court': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_crimin': [38, 82, 334, 389, 0, 1, 2, 3, 4, 5],\n",
       " 'account_dark': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_defend': [147, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_demonstr': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_deplor': [401, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_discriminatori': [533, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_egregi': [94, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_enforc': [52, 527, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'account_engag': [597, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_establish': [520, 464, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'account_extraordinari': [601, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_fact': [655, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_fail': [301, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_find': [649, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_former': [133, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_found': [569, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_fullest': [206, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_horrif': [219, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_hous': [497, 515, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'account_illeg': [76, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_illustr': [213, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_incid': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_includ': [649, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_individu': [457, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_instructor': [291, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_insuffici': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_investig': [192, 498, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'account_mabon': [307, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_main': [515, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_major': [548, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_make': [650, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_mani': [230, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_materi': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_mechan': [671, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_meet': [656, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_member': [73, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_misguid': [57, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_neither': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_occur': [426, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_offic': [129, 336, 690, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'account_paramed': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_percent': [416, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_permit': [62, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_perpetr': [92, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_physic': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_polic': [416, 711, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'account_pose': [498, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_post': [480, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_prosecut': [221, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_prove': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_provid': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_public': [447, 458, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'account_regard': [671, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_replac': [649, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_reprehens': [167, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_repres': [178, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_resid': [649, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_review': [671, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_said': [73, 98, 276, 294, 312, 0, 1, 2, 3, 4],\n",
       " 'account_screenshot': [219, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_search': [504, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_seek': [689, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_send': [193, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_serious': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_serv': [246, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_supervisori': [671, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_system': [611, 632, 649, 655, 689, 716, 0, 1, 2, 3],\n",
       " 'account_terribl': [285, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_testimoni': [178, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_titl': [321, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_today': [291, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_type': [105, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_use': [495, 476, 487, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'account_user': [504, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_vari': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_violat': [85, 108, 169, 238, 352, 400, 0, 1, 2, 3],\n",
       " 'account_walker': [194, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'account_wit': [520, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accru_interest': [593, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accur_current': [585, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accur_honest': [376, 440, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accur_inform': [533, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accur_recit': [134, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accur_reflect': [634, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accur_voter': [634, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accur_without': [585, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accuraci_plaintiff': [457, 574, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'accus_commit': [399, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accus_corder': [177, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accus_crimin': [17, 36, 51, 65, 86, 122, 125, 252, 253, 0],\n",
       " 'accus_defend': [1, 6, 7, 16, 18, 19, 21, 22, 25, 29],\n",
       " 'accus_duke': [121, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accus_evid': [4, 30, 67, 139, 180, 0, 1, 2, 3, 5],\n",
       " 'accus_murder': [60, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accus_remain': [93, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accus_sexual': [333, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'accus_subject': [33, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acevedo_puerto': [179, 184, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'achiev_addit': [204, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_competit': [667, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_complianc': [204, 496, 693, 701, 0, 1, 2, 3, 4, 5],\n",
       " 'achiev_desegreg': [590, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_file': [204, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_full': [362, 696, 703, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'achiev_greatest': [590, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_home': [625, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_includ': [496, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_interest': [467, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_partial': [696, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_reform': [671, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_request': [204, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_result': [111, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_right': [610, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_serv': [672, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_settlement': [612, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_social': [667, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_time': [496, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_toward': [698, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'achiev_victim': [167, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ackal_also': [99, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ackal_charg': [90, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ackal_count': [146, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ackal_lieuten': [90, 146, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'ackal_relat': [146, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ackal_savoy': [90, 146, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'ackal_supersed': [146, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ackerman_shelbi': [32, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'ackerman_summer': [32, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_action': [134, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_appreci': [65, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_assault': [194, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_attack': [42, 143, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'acknowledg_connect': [507, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_day': [351, 371, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'acknowledg_download': [489, 508, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'acknowledg_fact': [406, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_fire': [278, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_forc': [212, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_intend': [8, 27, 64, 181, 0, 1, 2, 3, 4, 5],\n",
       " 'acknowledg_intent': [256, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_investig': [611, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_knew': [376, 440, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'acknowledg_member': [275, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_partner': [466, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acknowledg_submit': [40, 93, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'acknowledg_unlaw': [64, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acquaint_gasolin': [180, 221, 268, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'acquir_properti': [532, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acquir_young': [676, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acquit_davi': [108, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acquit_destruct': [495, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acquit_novemb': [99, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acquit_three': [57, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'acquit_violat': [111, 426, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'across_abdomen': [103, 275, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'across_agenc': [231, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_america': [632, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_back': [103, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_board': [325, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_bodi': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_build': [419, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_campus': [657, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_countri': [694, 688, 65, 372, 393, 545, 628, 630, 637, 647],\n",
       " 'across_face': [138, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_feder': [560, 582, 638, 686, 0, 1, 2, 3, 4, 5],\n",
       " 'across_five': [573, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_hate': [70, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_jurisdict': [601, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_nation': [134, 318, 406, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'across_north': [554, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_northern': [74, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_oregon': [667, 680, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'across_polic': [372, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_racial': [577, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_rais': [253, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_state': [64, 250, 319, 409, 450, 516, 534, 647, 0, 1],\n",
       " 'across_store': [283, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_street': [28, 189, 247, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'across_system': [534, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_town': [531, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_unit': [65, 370, 707, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'across_various': [325, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_victim': [138, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'across_wall': [278, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_accid': [349, 520, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_accord': [413, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_act': [74, 245, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_addit': [421, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_adult': [378, 461, 489, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_aggress': [176, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_alleg': [271, 453, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_also': [278, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_among': [49, 300, 385, 466, 494, 0, 1, 2, 3, 4],\n",
       " 'act_anonym': [388, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_anywher': [171, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_arson': [306, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_associ': [134, 686, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_author': [73, 76, 129, 336, 0, 1, 2, 3, 4, 5],\n",
       " 'act_base': [95, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_becam': [398, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_benjamin': [13, 89, 367, 530, 0, 1, 2, 3, 4, 5],\n",
       " 'act_betsi': [458, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_bigotri': [13, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_billi': [680, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_boy': [234, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_bridget': [634, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_brit': [9, 12, 14, 117, 0, 1, 2, 3, 4, 5],\n",
       " 'act_brought': [96, 106, 119, 126, 213, 240, 441, 0, 1, 2],\n",
       " 'act_carli': [15, 358, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_carlton': [128, 135, 169, 400, 0, 1, 2, 3, 4, 5],\n",
       " 'act_carol': [629, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_carri': [69, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_child': [375, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_children': [516, 541, 285, 319, 450, 0, 1, 2, 3, 4],\n",
       " 'act_clark': [194, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_clear': [308, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_coerc': [144, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_color': [314, 347, 436, 452, 0, 1, 2, 3, 4, 5],\n",
       " 'act_conduct': [281, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_corey': [108, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_court': [95, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_crimin': [294, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_curri': [618, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_daniel': [462, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_date': [202, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_david': [163, 288, 306, 575, 0, 1, 2, 3, 4, 5],\n",
       " 'act_defend': [87, 228, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_deliber': [6, 133, 393, 0, 1, 2, 3, 4, 5, 7],\n",
       " 'act_deputi': [309, 439, 480, 505, 0, 1, 2, 3, 4, 5],\n",
       " 'act_describ': [283, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_direct': [80, 469, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_discrimin': [264, 648, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_distraught': [212, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_distribut': [478, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_domest': [13, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_donchak': [55, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_drove': [379, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_eastern': [71, 169, 400, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_eight': [310, 338, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_evil': [134, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_femal': [215, 264, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_fuel': [10, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_fullest': [190, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_fundament': [437, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_gatekeep': [439, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_general': [41, 61, 97, 99, 101, 125, 166, 167, 169, 178],\n",
       " 'act_global': [424, 442, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_gratuit': [206, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_greenberg': [13, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_group': [298, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_hang': [190, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_harass': [394, 471, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_hate': [152, 3, 26, 61, 102, 113, 174, 182, 217, 232],\n",
       " 'act_hatr': [77, 80, 245, 254, 0, 1, 2, 3, 4, 5],\n",
       " 'act_held': [253, 315, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_incred': [328, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_individu': [147, 498, 518, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_inform': [417, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_inspector': [332, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_instil': [149, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_intent': [166, 254, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_interfer': [415, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_intimid': [95, 109, 245, 341, 384, 454, 543, 0, 1, 2],\n",
       " 'act_investig': [111, 261, 469, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_john': [109, 341, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_josh': [332, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_juri': [395, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_kelli': [618, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_ketchmark': [235, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_kevin': [668, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_larson': [139, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_lawrenc': [161, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_like': [74, 278, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_made': [215, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_mainten': [264, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_make': [144, 290, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_male': [413, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_manner': [567, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_martinez': [51, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_member': [432, 439, 505, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_mere': [228, 293, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_middl': [394, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_minor': [398, 443, 449, 461, 489, 588, 0, 1, 2, 3],\n",
       " 'act_miracl': [208, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_mother': [363, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_motiv': [2, 56, 91, 104, 105, 131, 168, 360, 389, 0],\n",
       " 'act_ncpd': [203, 527, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_neglig': [349, 520, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_northern': [658, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_obstruct': [92, 236, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_occur': [115, 293, 379, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_offic': [425, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_often': [71, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_patrick': [78, 120, 517, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_peopl': [218, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_perpetr': [187, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_person': [94, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_persuad': [524, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_pete': [361, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_peterman': [402, 557, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_phillip': [387, 499, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_physic': [16, 33, 43, 145, 152, 363, 0, 1, 2, 3],\n",
       " 'act_polic': [324, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_pose': [569, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_prejudic': [366, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_primari': [171, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_prosecut': [77, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_purchas': [167, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_racial': [47, 275, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_religi': [202, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_report': [77, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_rescu': [601, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_rick': [250, 450, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_said': [62, 233, 322, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_sandra': [166, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_secretari': [686, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_sentenc': [143, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_sergeant': [139, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_serious': [422, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_set': [278, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_sexual': [220, 238, 264, 357, 0, 1, 2, 3, 4, 5],\n",
       " 'act_shapiro': [491, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_special': [236, 250, 278, 289, 363, 388, 588, 0, 1, 2],\n",
       " 'act_specif': [349, 520, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_stephen': [245, 511, 627, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_steve': [544, 566, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_stood': [167, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_subject': [144, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_take': [238, 290, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_target': [440, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_terror': [202, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_testimoni': [167, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_third': [287, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_three': [319, 450, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_today': [303, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_togeth': [484, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_toler': [264, 358, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'act_traci': [379, 463, 528, 584, 0, 1, 2, 3, 4, 5],\n",
       " 'act_troyer': [383, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_unit': [10, 94, 99, 212, 215, 478, 662, 0, 1, 2],\n",
       " 'act_vandal': [394, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_victim': [223, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_vigor': [340, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_vile': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_violat': [118, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_violenc': [26, 91, 228, 405, 429, 11, 28, 41, 45, 54],\n",
       " 'act_western': [235, 242, 306, 356, 0, 1, 2, 3, 4, 5],\n",
       " 'act_will': [349, 520, 133, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'act_william': [595, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_without': [388, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'act_witthar': [288, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_across': [630, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_address': [663, 668, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_anytim': [635, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_around': [532, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_base': [429, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_brought': [279, 457, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_case': [599, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_cast': [276, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_caus': [129, 336, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_charg': [250, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_commit': [158, 315, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_compani': [540, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_complet': [698, 706, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_compli': [659, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_compliant': [706, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_continu': [441, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_convict': [19, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_correct': [460, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_corrod': [76, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_creat': [557, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_crimin': [178, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_critic': [602, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_defend': [164, 194, 211, 226, 230, 240, 335, 458, 0, 1],\n",
       " 'action_employ': [561, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_enforc': [639, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_ensur': [175, 556, 674, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_erod': [445, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_event': [663, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_everyday': [259, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_fals': [219, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_feder': [164, 602, 684, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_femal': [144, 215, 264, 290, 0, 1, 2, 3, 4, 5],\n",
       " 'action_fight': [77, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_file': [204, 496, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_great': [546, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_grossli': [455, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_group': [116, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_hate': [92, 295, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_help': [651, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_hold': [193, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_hope': [74, 295, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_implement': [681, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_includ': [342, 664, 679, 692, 0, 1, 2, 3, 4, 5],\n",
       " 'action_individu': [460, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_investig': [334, 355, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_involv': [1, 93, 0, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_johnson': [119, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_landlord': [574, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_lane': [667, 680, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_lawsuit': [667, 680, 671, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_like': [458, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_list': [201, 223, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_longer': [225, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_look': [627, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_make': [664, 679, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_mass': [662, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_mcdonald': [645, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_miss': [147, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_motiv': [134, 174, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_noth': [219, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_object': [349, 520, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_offend': [93, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_offic': [110, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_ongo': [153, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_openshaw': [148, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_order': [15, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_overcom': [692, 702, 705, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_penalti': [506, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_perpetr': [304, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_plan': [496, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_polic': [267, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_practic': [655, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_promot': [119, 201, 223, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_protect': [308, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_public': [706, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_reason': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_reflect': [445, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_religi': [68, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_remedi': [216, 616, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_remind': [560, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_rental': [570, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_report': [630, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_repres': [246, 334, 531, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_request': [204, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_requir': [659, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_result': [240, 312, 352, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_safeguard': [361, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_said': [94, 259, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_serv': [77, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_set': [256, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_show': [455, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_specif': [361, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_stuff': [433, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_support': [334, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_take': [60, 391, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_taken': [614, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_tarnish': [406, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_threaten': [198, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_took': [656, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_undermin': [73, 87, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_undertaken': [276, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_unit': [253, 340, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_unjustifi': [108, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_unlaw': [238, 299, 535, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'action_unreason': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_victim': [3, 26, 276, 0, 1, 2, 4, 5, 6, 7],\n",
       " 'action_violat': [172, 500, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'action_well': [556, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_will': [349, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_women': [238, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_worcest': [471, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'action_would': [139, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'activ_abus': [439, 505, 0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'activ_access': [201, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'activ_accord': [344, 451, 462, 493, 0, 1, 2, 3, 4, 5],\n",
       " 'activ_act': [163, 173, 516, 0, 1, 2, 3, 4, 5, 6],\n",
       " 'activ_administ': [157, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'activ_agreement': [700, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'activ_also': [519, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'activ_approxim': [462, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_bigrams_per_topic = get_topwords(dtm_bigram, 10)\n",
    "top_bigrams_per_topic\n",
    "\n",
    "#double checked "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optional extra credit (2 points)\n",
    "\n",
    "You notice that the pharmaceutical kickbacks press release we analyzed in question 1 was for an indictment, and that in the original data, there's not a clear label for whether a press release outlines an indictment (charging someone with a crime), a conviction (convicting them after that charge either via a settlement or trial), or a sentencing (how many years of prison or supervised release a defendant is sentenced to after their conviction).\n",
    "\n",
    "You want to see if you can identify pairs of press releases where one press release is from one stage (e.g., indictment) and another is from a different stage (e.g., a sentencing).\n",
    "\n",
    "You decide that one way to approach is to find the pairwise string similarity between each of the processed press releases in `doj_subset`. There are many ways to do this, so Google for some approaches, focusing on ones that work well for entire documents rather than small strings.\n",
    "\n",
    "Find the top two pairs (so four press releases total)-- do they seem like different stages of the same crime or just press releases covering similar crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_different_stages(text1, text2):\n",
    "    stage_patterns = {\n",
    "        'indictment': re.compile(r'\\bindict\\w*\\b', re.IGNORECASE),\n",
    "        'conviction': re.compile(r'\\bconvict\\w*\\b', re.IGNORECASE),\n",
    "        'sentencing': re.compile(r'\\bsentenc\\w*\\b', re.IGNORECASE)\n",
    "    }\n",
    "    \n",
    "    found_stages_text1 = {stage: bool(pattern.search(text1)) for stage, pattern in stage_patterns.items()}\n",
    "    found_stages_text2 = {stage: bool(pattern.search(text2)) for stage, pattern in stage_patterns.items()}\n",
    "\n",
    "    return any(found_stages_text1[stage] != found_stages_text2[stage] for stage in stage_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs identified: 77\n",
      "Similarity between Press Release 530 and Press Release 555: 0.9442\n",
      "Press Release 530 (Stage Check):\n",
      "church hill maryland resid sentenc today year prison follow lifetim term supervis releas entic minor engag sexual activ attempt transfer obscen materi minor announc act general kenneth blanco crimin act benjamin greenberg southern florida robert moor plead guilti march judg daniel hurley southern florida moor employ secret assign white hous time arrest remain custodi sinc time moor sinc termin secret servic posit accord admiss made connect plea moor maintain profil social media applic provid platform exchang digit imag well voic text messag delawar state polic detect delawar child predat task forc creat profil site pose girl moor engag number onlin chat session mobil app period includ moor work number onlin chat moor undercov offic pose femal minor sexual natur sever occas moor sent pictur includ sexual explicit imag accord plea document arrest enforc discov moor communic minor florida moor admit communic sent sexual explicit imag entic minor send sexual explicit photo well moor engag type behavior girl texa anoth girl missouri moor request feder charg delawar transfer southern florida could plead guilti charg time immigr custom enforc homeland secur investig delawar child predat task forc investig austin berri crimin child exploit obscen section ceo corey steinberg southern florida prosecut delawar brought part project safe childhood nationwid initi combat grow epidem child sexual exploit abus launch attorney offic ceo project safe childhood marshal feder state local resourc better locat apprehend prosecut individu exploit children internet well identifi rescu victim inform project safe childhood pleas visit http\n",
      "\n",
      "Press Release 555 (Stage Check):\n",
      "church hill maryland resid plead guilti today feder court count entic minor engag sexual activ count attempt transfer obscen materi minor announc act general kenneth blanco crimin wifredo ferrer southern florida robert moor plead guilti today judg daniel hurley southern florida moor employ secret assign white hous time arrest remain custodi sinc time moor sinc termin secret servic posit accord admiss made connect plea moor maintain profil social media applic provid platform exchang digit imag well voic text messag delawar state polic detect delawar child predat task forc creat profil site pose girl moor engag number onlin chat session mobil app period includ moor work number onlin chat moor undercov offic pose femal minor sexual natur sever occas moor sent pictur includ sexual explicit imag accord plea document arrest enforc discov moor communic minor florida moor admit communic sent sexual explicit imag entic minor send sexual explicit photo well moor engag type behavior girl texa anoth girl missouri moor request feder charg delawar transfer southern florida could plead guilti charg time immigr custom enforc homeland secur investig delawar child predat task forc investig austin berri crimin child exploit obscen section ceo corey steinberg southern florida prosecut brought part project safe childhood nationwid initi combat grow epidem child sexual exploit abus launch attorney offic ceo project safe childhood marshal feder state local resourc better locat apprehend prosecut individu exploit children internet well identifi rescu victim inform project safe childhood pleas visit http\n",
      "\n",
      "Similarity between Press Release 163 and Press Release 173: 0.8985\n",
      "Press Release 163 (Stage Check):\n",
      "coerc sexual explicit photo video minor distribut internet plead guilti coercion entic minor engag sexual activ act general kenneth blanco crimin act david weiss delawar made announc justin gulisano newark york charg march plead guilti judg leonard stark delawar accord admiss made connect plea agreement gulisano victim onlin victim year gulisano began request receiv sexual explicit imag video victim gulisano post sexual explicit video victim pornographi websit download post repost viewer addit pornograph websit victim refus make send addit imag video gulisano respond threaten victim occas threaten post victim imag video internet threaten share imag video victim brother threaten victim life immigr custom enforc homeland secur investig delawar child predat task forc investig lauren britsch crimin child exploit obscen section ceo graham robinson delawar prosecut brought part project safe childhood nationwid initi combat grow epidem child sexual exploit abus launch attorney offic ceo project safe childhood marshal feder state local resourc better locat apprehend prosecut individu exploit children internet well identifi rescu victim inform project safe childhood pleas visit\n",
      "\n",
      "Press Release 173 (Stage Check):\n",
      "solicit sexual explicit photo video minor distribut internet sentenc month prison follow year supervis releas plead guilti coercion entic minor engag sexual activ act general john cronan crimin david weiss delawar made announc sentenc judg leonard stark delawar justin gulisano emma alexand gulisano newark york charg march plead guilti accord admiss made connect plea agreement gulisano victim onlin victim year gulisano began request receiv sexual explicit imag video victim gulisano post sexual explicit video victim pornographi websit download post repost viewer addit pornograph websit eventu victim refus make send addit imag video gulisano respond threaten victim occas threaten post victim imag video internet threaten share imag video victim brother threaten victim life immigr custom enforc homeland secur investig delawar child predat task forc investig lauren britsch crimin child exploit obscen section ceo graham robinson delawar prosecut brought part project safe childhood nationwid initi combat grow epidem child sexual exploit abus launch attorney offic ceo project safe childhood marshal feder state local resourc better locat apprehend prosecut individu exploit children internet well identifi rescu victim inform project safe childhood pleas visit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doj_subset_wscore['processed_text'] = doj_subset_wscore['processed_text'].fillna('')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doj_subset_wscore['processed_text'])\n",
    "\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def check_different_stages(text1, text2):\n",
    "    stage_patterns = {\n",
    "        'indictment': re.compile(r'\\bindict\\w*\\b', re.IGNORECASE),\n",
    "        'conviction': re.compile(r'\\bconvict\\w*\\b', re.IGNORECASE),\n",
    "        'sentencing': re.compile(r'\\bsentenc\\w*\\b', re.IGNORECASE)\n",
    "    }\n",
    "    found_stages_text1 = {stage: bool(pattern.search(text1)) for stage, pattern in stage_patterns.items()}\n",
    "    found_stages_text2 = {stage: bool(pattern.search(text2)) for stage, pattern in stage_patterns.items()}\n",
    "    return any(found_stages_text1[stage] != found_stages_text2[stage] for stage in stage_patterns)\n",
    "\n",
    "n = len(doj_subset_wscore)\n",
    "top_pairs = []\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        if cosine_sim[i, j] > 0.5:  \n",
    "            if check_different_stages(doj_subset_wscore.iloc[i]['processed_text'], doj_subset_wscore.iloc[j]['processed_text']):\n",
    "                top_pairs.append(((i, j), cosine_sim[i, j]))\n",
    "\n",
    "top_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "top_two_pairs = top_pairs[:2]\n",
    "\n",
    "print(f\"Total pairs identified: {len(top_pairs)}\")\n",
    "for pair, similarity in top_two_pairs:\n",
    "    i, j = pair\n",
    "    print(f\"Similarity between Press Release {i} and Press Release {j}: {similarity:.4f}\")\n",
    "    print(f\"Press Release {i} (Stage Check):\\n{doj_subset_wscore.iloc[i]['processed_text']}\\n\")\n",
    "    print(f\"Press Release {j} (Stage Check):\\n{doj_subset_wscore.iloc[j]['processed_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Press Release 530 and Press Release 555\n",
    "# Press release 530 focuses on the sentencing details of an individual involved in\n",
    "#enticing minors and distributing obscene material \n",
    "# Press release 555 focuses on the same individual pleading guilty to related charges \n",
    "# in federal court "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press Release 163 and Press Release on 173\n",
    "# Press release 163 focuses on the guilty plea of an individual charged with \n",
    "#coercing minors into providing sexually explicit photos/videos \n",
    "# Press release 173 focuses on the sentencing of the same individual, highlighting \n",
    "# the prison term and supervised release following the guilty plea "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
